[["index.html", "Untitled Section 1 Introduction", " Untitled Tran Le 2022-10-10 Section 1 Introduction This book-down file is where I keep the observations/tricks I got while using R. I also use this file to write some cheat sheets for later quick reference. Sometimes, I write something when my friends ask me a question. I believe explaining to someone is an excellent way to help me understand and learn better. These are my LinkedIn and GitHub pages. Please connect so that we can learn from each other. Happy studying ! data_disp &lt;- function(x){ # x: a datafarme gotton from xcov_results(xcov, data_use) x %&gt;% datatable(rownames = F, extensions = &#39;Buttons&#39;, options = list( pageLength = 200, dom = &#39;Brt&#39;, buttons = c(&#39;copy&#39;, &#39;csv&#39;, &#39;excel&#39;, &#39;pdf&#39;, &#39;print&#39;)))} "],["github-cheatsheet.html", "Section 2 Github-Cheatsheet 2.1 Introduction 2.2 Connecting an existing Rstudio project to Github. 2.3 Integrate Rstudio with an existing project on Github 2.4 How to post your Bookdown file to Github 2.5 Some most common git commands. 2.6 References", " Section 2 Github-Cheatsheet 2.1 Introduction This is a cheat sheet for using Github with R, including: Connecting an existing Rstudio project to Github. Integrate Rstudio with an existing project on Github. How to post your Bookdown file to Github. Side note: Some most common git commands. I have learned about Git and Github from here and from GitHub Docs. The content of this cheat sheet mainly gotten from here. 2.2 Connecting an existing Rstudio project to Github. When you have an R project on your computer and want to post it on your GitHub page one day, this part can help you do that. Step 1: Creating our local git repository In Rstudio , go to Tools \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Project Setup \\(\\rightarrow\\) This will bring you to Project Options panel. In this panel, in Version control system, choose Git , click OK. Then you can choose to use Git tab or Git commands to process steps after creating repository on GitHub. Step 2: Creating repository on GitHub. In this step, skip all of the check boxes for Add a README file, Add. gitignore, Choose a license. Click Create repository. After this step, you will have a Quick Setup screen that have some Git commands that you could use, such as: To create a new repository on the command line git init git add README.md git commit -m “first commit” git branch -M main git remote add origin git@github.com:your_GitHub_account_name/your_repository_name.git git push -u origin main To push an existing repository from the command line git remote add origin git@github.com:your_GitHub_account_name/your_repository_name.git git branch -M main git push -u origin main Step3: Connect local repository to GitHub Go to Terminal tab, paste the commandS in (2b) to connect and push your R project to your GitHub repository. 2.3 Integrate Rstudio with an existing project on Github Step 1: Clone your repository to create a Rstudio project From your GitHub repository -&gt; click on Code -&gt; copy the content clone from SSH, In Rstudio -&gt; New Project -&gt; Version Control -&gt; Git -&gt; In the repository URL, paste the link you got above (the copied SSH link). In the Project directory name, type the name of the project that you want to use (recommend to use the same name with your GitHub repository) In the Create project as a subdirectory of: browse the place you want to keep the project on your computer. Then click “Create Project”. After this step, you have a Rproject that is cloned from your Github repository. Step 2: modify your Rproject and push it back to your GitHub repository. (Optional) Modify the Rproject/Rbook-down …, build your book-down file,… (Optional) Update the gitignore file if you have some files/folders that you don’t want to push into your GitHub page. Click on Git, check the changes (check boxes) that you want to commit, input the Commit message, then click Commit. Click on Push to push your project to the Github page. 2.4 How to post your Bookdown file to Github Create a book-down project with the format gitbook. After that, init the git init in the terminal, commit all of the files, Go to output.yml to comment the bookdown:pdf_book and bookdown::epub_book: default so that we only create the gitbook file when we init. Go to the bookdown.yml file; we change where the output will be placed. Change from this: To this: delete_merged_file: true language:     ui:   chapter_name: “Chapter “ delete_merged_file: true output_dir: “docs” language:    ui:     chapter_name: “Chapter “ Go to the .gitignor file, and add \\(\\_\\)bookdown_files in the file. Git add docs/, commit, push all things on github. In GitHub, on Settings, go to Pages =&gt; GitHub Pages =&gt; change it to main, /docs . Then the link to your book is found in Your site is published at: 2.5 Some most common git commands. To use these commands on RStudio, you will need to come to Terminal and type the commands. - git config –global user.name “[name]”: sets author name. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD - git config –global user.email “your_email@example.com”: sets author email id. ======= - git config –global user.email “[email address]”: sets author email id. &gt;&gt;&gt;&gt;&gt;&gt;&gt; a0f7d01cfa45f6a4da7bbf9814f0db459eaf7a20 - git init [repository_name]: start new repository. - git clone [url]: obtains a repository from an existing URL. - git status: lists all the files that have to be committed. - git commit -am [your_commit_message]: commits any files you’ve changed or added. - git push -u origin main: sends the committed changes of origin branch to your remote repository. 2.6 References Git and GitHub for Beginners - Crash Course - Youtube Git Commands (taken from the above tutorial) How to intall git Generating a new SSH key and adding it to the ssh-agent Youtube Integrating RStudio with a new or existing project on GitHub (CC120) "],["r-resources-from-absolute-beginners-to-more-advance.html", "Section 3 R resources from absolute beginners to more advance 3.1 Introduction 3.2 For absolute beginners. 3.3 R graphs galleries 3.4 Some R excellent books", " Section 3 R resources from absolute beginners to more advance 3.1 Introduction It may not be a good idea to put this section here. But today, I went to the Mississippi Public Health Association ’s World Field Epidemiology Day Workshop. I meet some new friends there who study Epidemiology that want to learn R. I think I need to share these really good and free  resources. The resources will be listed from the absolute beginner to more advanced levels. If you have any suggestions or want to add more resources about the topic that you want to learn, please let me know (here is my LinkedIn account). I will update and correct this according to that. 3.2 For absolute beginners. MarinStatsLectures-R Programming &amp; Statistics was the first teacher that taught me the first steps in R. This Chanel contains many topics that you can learn. This is the first series that you need to watch if you know nothing about R. This will teach you how to install R, R studio, install R packages, import your data… Then you can explore other playlists from him if you are interested. 3.3 R graphs galleries I have seen you people discuss a lot about how to use graphs. This link, https://r-graph-gallery.com/ will give you a quick tutorial on creating those plots. Please click on the plot you want, for example, Barplot, then it will take you to the page with many bar plots and instructions. This is the link I got after choosing the most basic bar plot from the main page: [https://r-graph-gallery.com/218-basic-barplots-with-ggplot2.html]. Another library we can use to create plots is Plotly. Here is the link to the Plotly gallery: https://plotly.com/r/. Similarly, click the plot you want to make and have the code on your hands. (I personally use ggplot2 more frequently than Plotly). 3.4 Some R excellent books R for Data Science is the book everyone who studies R needs to read. It teaches you how to do Data Visualization, Data Wrangling, and many more. We also have cheat sheets that are associated with this book. You can download them from here. Advanced R, as its name says about itself, is an advanced R book. I have not read these two books, but I think they may be helpful for you. R for Epidemiology and R for applied epidemiology and public health "],["problems-when-using-dplyrfull_join.html", "Section 4 Problems when using dplyr::full_join 4.1 Introduction 4.2 Using dplyr::full_join 4.3 Using powerjoin::power_full_join 4.4 What if we have conflict data sets 4.5 References", " Section 4 Problems when using dplyr::full_join library(powerjoin) library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.1 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ✔ purrr 0.3.4 ## Warning: package &#39;stringr&#39; was built under R version 4.2.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() 4.1 Introduction This part will explore some problems that we may cope with when using dplyr::full_join, and it is why powerchoice::power_full_join may come in handy. Assume that we have two people: name = John, age = 30, sex = “M”, treatment = NA (we don’t know John’s treatment) name = Marry, age = 45, sex = “F”, treatment = “A” However, we have multiple data sets that contain incomplete information about these two people. Let us consider the data that we have and the problems that we might have to cope with while trying to get data that contains as much information as possible from these two people by joining our available data sets. 4.2 Using dplyr::full_join First, let us consider the below data set. With this data set, we will get the same result while using dfs %&gt;% reduce(full_join) and dfs %&gt;% reduce(full_join, by= name). We do not see any problem here, and we collect all the information from our available data sets. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;) ) dfs %&gt;% reduce(full_join) ## Joining, by = &quot;name&quot; ## Joining, by = &quot;name&quot; ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A dfs %&gt;% reduce(full_join, by=&quot;name&quot;) ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A However, let us consider when our dfs list has one more row (the fourth row) with the name and age of Mary. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45) ) The full_join without identifying the key by=\"name\" may think that there are two people with the same name, “Mary”. dfs %&gt;% reduce(full_join) ## Joining, by = &quot;name&quot; ## Joining, by = &quot;name&quot; ## Joining, by = c(&quot;name&quot;, &quot;age&quot;) ## # A tibble: 3 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A ## 3 Mary 45 &lt;NA&gt; &lt;NA&gt; The full_join with identifying the key by=\"name\"creates extra columns when we have duplicated column names dfs %&gt;% reduce(full_join, by = &quot;name&quot;) ## # A tibble: 2 × 5 ## name age.x sex treatment age.y ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John 30 M &lt;NA&gt; NA ## 2 Mary NA F A 45 We may think about how to delete these extra columns by doing like below code chunk. However, by doing this, we lost the information about Mary’s age (which was available in the age.y column above). dfs %&gt;% reduce(full_join, by = &quot;name&quot;, suffix = c(&quot;&quot;, &quot;.y&quot;)) %&gt;% select(-ends_with(&quot;.y&quot;)) ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A 4.3 Using powerjoin::power_full_join Solve the problem using powerjoin. Let’s consider the dfs list with one more row. The problems we have when using dplyr::full_join and how powerjoin::power_full_join can be helpful. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45), fifth = tibble(name = &quot;Mary&quot;, sex = &quot;F&quot;) ) dfs %&gt;% reduce(full_join) ## Joining, by = &quot;name&quot; ## Joining, by = &quot;name&quot; ## Joining, by = c(&quot;name&quot;, &quot;age&quot;) ## Joining, by = c(&quot;name&quot;, &quot;sex&quot;) ## # A tibble: 3 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A ## 3 Mary 45 &lt;NA&gt; &lt;NA&gt; dfs %&gt;% reduce(full_join, by = &quot;name&quot;) ## # A tibble: 2 × 6 ## name age.x sex.x treatment age.y sex.y ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; NA &lt;NA&gt; ## 2 Mary NA F A 45 F The powerjoin package helps us collect all available information. dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_xy) ## # A tibble: 2 × 4 ## name treatment age sex ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 John &lt;NA&gt; 30 M ## 2 Mary A 45 F 4.4 What if we have conflict data sets Now, consider that we have two data sets for Mary that have different values for “age” (the fourth and fifth), with ages equal to 45 and 65, respectively. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45), fifth = tibble(name = &quot;Mary&quot;, age = 65) ) Then the argument conflict = coalesce_xy will take the first available value (age = 45), while conflict = coalesce_yx will take the second available value (age = 65). dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_xy) ## # A tibble: 2 × 4 ## name sex treatment age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John M &lt;NA&gt; 30 ## 2 Mary F A 45 dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_yx) ## # A tibble: 2 × 4 ## name sex treatment age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John M &lt;NA&gt; 30 ## 2 Mary F A 65 4.5 References https://github.com/moodymudskipper/powerjoin "],["load-and-write-to-an-excel-sheet.html", "Section 5 Load and write to an excel sheet 5.1 Introduction 5.2 Code", " Section 5 Load and write to an excel sheet 5.1 Introduction This section can be considered as a cheat sheet for loading and writing to an excel sheet. 5.2 Code library(openxlsx) # Put in HTML result table source(&quot;utilities.R&quot;) wb &lt;- loadWorkbook(&quot;location/Your_Excel_File_Name.xlsx&quot;) sheetname =&quot;Sheet_name_that_you_want_to_write_on&quot; # You can write many table/content that you want in a sheet using writeData writeData(wb, sheetname, table_you_want_to_write_on, startRow = 11, startCol = &quot;F&quot;, colNames = F) # Open a temporary version to check if we have the correct way that we want our data to be written in the Excel sheet file. openXL(wb) # Then you can write the file with new/old name. saveWorkbook(wb = wb, file = &quot;location/Your_New/Old_Excel_File_Name.xlsx&quot;,overwrite = T) "],["replace-values-by-nasa-specfic-value.html", "Section 6 Replace Values by Nas/A specfic value 6.1 Introduction 6.2 replace_with_na(): replace specific value(s) at in specific columns by NAs. 6.3 replace_with_na_all() Replaces some values by NA for all columns. 6.4 replace_with_na_at(): replaces some chosen values in a chosen set of columns by NAs. 6.5 replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NA. 6.6 A helpfull observation using mutate_at and replace 6.7 References", " Section 6 Replace Values by Nas/A specfic value 6.1 Introduction We will explore some cases in which we can quickly change some values to NAs. Some useful commands (from the library naniar) include: replace_with_na(): replace specific value(s) at in specific columns by NAs. replace_with_na_all(): Replaces some values by NAs for all columns. replace_with_na_at(): Replaces some chosen values in a chosen set of columns by NAs. replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NAs. suppressPackageStartupMessages(library(tidyverse)) library(naniar) Let’s first create a data example. You can see that the data_example that we create here represents what we would expect if we have a character value in a numerical column if we read data from a CSV file. For example, column y is a column with numerical values, but since there is NR (NR means not reported) in the column, R will think it is a character column when we read the data. data_example&lt;- tribble( ~name, ~x, ~y, ~z, ~t, &quot;Mr.A&quot;, &quot;a&quot;, &quot;2&quot;, &quot;3.6&quot;, &quot;na&quot;, &quot;Mr.B&quot;, &quot;b&quot;, &quot;1&quot;, &quot;.&quot;, &quot;2.1&quot;, &quot;Ms. C&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;10&quot;, &quot;3.4&quot;, &quot;Ms. D&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;1&quot;) data_example ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C NR NR 10 3.4 ## 4 Ms. D NR NR NR 1 6.2 replace_with_na(): replace specific value(s) at in specific columns by NAs. replace_with_na replaces a list of values in a list of columns by Na, where each column has different values that we want to replace. We may need to use this in case a value should be converted to NA in a column but not in another column. For example, we want to convert NR to NA in column x, but do not want to do so with column z (with column z, we only want to convert “.” to NAs but keep NR as it is). data_example %&gt;% naniar::replace_with_na(replace = list(x = c(&quot;NR&quot;), y = c(&quot;NR&quot;), z = c(&quot;.&quot;))) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; NR 1 6.3 replace_with_na_all() Replaces some values by NA for all columns. Here, we want to replace a value “NR” by NAs. data_example %&gt;% replace_with_na_all(., condition = ~.x == &quot;NR&quot;) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 In case we want to replace many more values by NA, we can use \\(%in%\\) as below data_example %&gt;% replace_with_na_all(., condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 6.4 replace_with_na_at(): replaces some chosen values in a chosen set of columns by NAs. Replace “NR” and “.” at columns x and y with NAs: data_example %&gt;% replace_with_na_at(.var=c(&quot;x&quot;, &quot;y&quot;), condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; NR 1 6.5 replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NA. data_example %&gt;% replace_with_na_if(is_character, condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 6.6 A helpfull observation using mutate_at and replace Besides of replace values by Na. We also can replace specific values by a value in some selected columns. One example can be data_example %&gt;% mutate_at(c(&quot;name&quot;), ~replace(., .%in% c(&quot;Mr.A&quot;, &quot;Mr.B&quot;), &quot;The AB&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 The AB a 2 3.6 na ## 2 The AB b 1 . 2.1 ## 3 Ms. C NR NR 10 3.4 ## 4 Ms. D NR NR NR 1 6.7 References https://www.rdocumentation.org/packages/naniar/versions/0.6.1/topics/replace_with_na "],["find-group-of-highly-correlated-columns.html", "Section 7 Find group of highly correlated columns 7.1 Introduction 7.2 Data set and the code to get the result 7.3 Explain the code in details 7.4 Deal with nominal-nominal variables 7.5 Here is the code to get group of highly correlated columns 7.6 Explain the steps in details 7.7 References", " Section 7 Find group of highly correlated columns 7.1 Introduction Here, we will explore how to find groups of highly correlated columns. Each group contains columns having a correlation higher than a fixed chosen threshold. We will first give a simple data set, then give the code and the result we get. After all, we will explore how the code works. This example based on the question and answer that I got from stackoverflow.com. Some of the functions have been updated since the package is updated at the time I wrote this section (2022). Besides exploring how to find groups of highly correlated numerical columns, I also do the same with (binary) nominal columns. However, since no command helps compute the correlation matrix with a numerical column, we will need to process this step slightly differently than the above example. This way can be applied if we want to find other kinds of groups of highly correlated variables, such as numeric-numeric and numeric-ordinal,… 7.2 Data set and the code to get the result suppressPackageStartupMessages(library(tidyverse)) suppressPackageStartupMessages(library(igraph)) suppressPackageStartupMessages(library(DescTools)) suppressPackageStartupMessages(library(psych)) data1 &lt;- structure(list(A = c(1L, 2L, 5L, 4L, 366L, 65L, 43L, 456L, 876L, 78L, 687L, 378L, 378L, 34L, 53L, 43L), B = c(2L, 2L, 5L, 4L, 366L, 65L, 43L, 456L, 876L, 78L, 687L, 378L, 378L, 34L, 53L, 41L), C = c(10L, 20L, 10L, 20L, 10L, 20L, 1L, 0L, 1L, 2010L,20L, 10L, 10L, 10L, 10L, 10L), D = c(2L, 10L, 31L, 2L, 2L, 5L, 2L, 5L, 1L, 52L, 1L, 2L, 52L, 6L, 2L, 1L), E = c(4L, 10L, 31L, 2L, 2L, 5L, 2L, 5L, 1L, 52L, 1L, 2L, 52L, 6L, 2L, 3L)), .Names = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), class = &quot;data.frame&quot;, row.names = c(NA,-16L)) Here is the code that we can use to get the result # Compute correlation of columns in data1 using pearson var.corelation &lt;- cor(as.matrix(data1), method=&quot;pearson&quot;) # prevent duplicated pairs var.corelation &lt;- var.corelation*lower.tri(var.corelation) # Filter pairs having correlation &gt; threshold check.corelation &lt;- which(abs(var.corelation)&gt;0.62, arr.ind=TRUE) graph.cor &lt;- graph_from_data_frame(check.corelation, directed = FALSE) # groups.cor &lt;- split(unique(as.vector(check.corelation)), clusters(graph.cor)$membership) # Get the row name of highly correlated groups lapply(groups.cor,FUN=function(list.cor){rownames(var.corelation)[list.cor]}) ## $`1` ## [1] &quot;B&quot; &quot;A&quot; ## ## $`2` ## [1] &quot;D&quot; &quot;E&quot; &quot;C&quot; If our data has a small number of columns, we can plot groups of highly correlated columns. The below graph gives indexed highly correlated clusters. plot(graph.cor, vertex.label = V(graph.cor)$name) 7.3 Explain the code in details First, notice that our data only contains numeric columns; we can compute a correlation matrix using Pearson correlation. var.corelation &lt;- cor(as.matrix(data1), method=&quot;pearson&quot;) var.corelation ## A B C D E ## A 1.0000000 0.9999978 -0.1385469 -0.1125711 -0.1242381 ## B 0.9999978 1.0000000 -0.1384694 -0.1124062 -0.1240949 ## C -0.1385469 -0.1384694 1.0000000 0.6212136 0.6220380 ## D -0.1125711 -0.1124062 0.6212136 1.0000000 0.9992690 ## E -0.1242381 -0.1240949 0.6220380 0.9992690 1.0000000 Since the correlation matrix is symmetric through the diagonal and the values on the diagonal are equal to 1, we just need to keep the values in the lower diagonal. lower.tri(var.corelation) ## [,1] [,2] [,3] [,4] [,5] ## [1,] FALSE FALSE FALSE FALSE FALSE ## [2,] TRUE FALSE FALSE FALSE FALSE ## [3,] TRUE TRUE FALSE FALSE FALSE ## [4,] TRUE TRUE TRUE FALSE FALSE ## [5,] TRUE TRUE TRUE TRUE FALSE var.corelation &lt;- var.corelation*lower.tri(var.corelation)- var.corelation With this example, we only filter columns with a correlation &gt; 0.62. The result below shows us the location row and columns of highly correlated pairs. For example, The first one is (row 2, column 1) associated with (B, A) is a pair of columns having correlation &gt; threshold, etc. threshold = 0.62 check_corelation &lt;- which(abs(var.corelation)&gt;0.62, arr.ind=TRUE) check_corelation ## row col ## A 1 1 ## A 1 2 ## B 2 2 ## C 3 3 ## C 3 4 ## D 4 4 ## C 3 5 ## D 4 5 ## E 5 5 graph.cor &lt;- graph_from_data_frame(check.corelation, directed = FALSE) graph.cor ## IGRAPH 671e094 UN-- 5 4 -- ## + attr: name (v/c) ## + edges from 671e094 (vertex names): ## [1] 2--1 4--3 5--3 4--5 Now, we will consider the clusters’ membership used to split our data. From the membership, the first row is the indexes of columns, and the second row is the index of the cluster that those columns belong to. We see that column with indexes 2 and 1 (columns B and A) is in cluster 1, and columns with indexes 4, 5, and 3 (columns D, E, and C) are in cluster 2. components(graph.cor) ## $membership ## 2 4 5 1 3 ## 1 2 2 1 2 ## ## $csize ## [1] 2 3 ## ## $no ## [1] 2 So, now we split the column indexes into cluster unique(as.vector(check.corelation)) ## [1] 2 4 5 1 3 groups.cor &lt;- split(unique(as.vector(check.corelation)), components(graph.cor)$membership) groups.cor ## $`1` ## [1] 2 1 ## ## $`2` ## [1] 4 5 3 And get the column names of the columns in each cluster. lapply(groups.cor,FUN=function(list.cor){rownames(var.corelation)[list.cor]}) ## $`1` ## [1] &quot;B&quot; &quot;A&quot; ## ## $`2` ## [1] &quot;D&quot; &quot;E&quot; &quot;C&quot; 7.4 Deal with nominal-nominal variables set.seed(365263) X1 &lt;- sample(c(&quot;A&quot;, &quot;B&quot;), size = 16, replace = TRUE) X2 &lt;- sample(c(&quot;E&quot;, &quot;H&quot; ), size = 16, replace = TRUE) X3 &lt;- sample(c(&quot;X&quot;, &quot;Y&quot;), size = 16, replace = TRUE) X4 &lt;- sample(c(&quot;L&quot;, &quot;M&quot;), size = 16, replace = TRUE) X5 &lt;- sample(c(&quot;K&quot;, &quot;L&quot;), size = 16, replace = TRUE) data2 &lt;- tibble(X1, X2, X3, X4, X5) head(data2) ## # A tibble: 6 × 5 ## X1 X2 X3 X4 X5 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B H X M L ## 2 B H Y M K ## 3 A H Y L L ## 4 B E Y L L ## 5 B E Y L L ## 6 B H X M L 7.5 Here is the code to get group of highly correlated columns colname &lt;- colnames(data2) pair_cols&lt;- combn(colname, 2) %&gt;% t %&gt;% as_tibble() ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. ## Using compatibility `.name_repair`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. com_phi_f &lt;-function(var1, var2){return(phi(table(var1, var2)))} # Create a vector that contain phi corr(V1, V2) for all of pairs nom_cor &lt;- c() for (i in 1:dim(pair_cols)[1]){ # get the values of the variable associated with variable #pair_cols$V1[row==i] and pair_cols$V2[row==i] var1 &lt;- data2 %&gt;% select(all_of(pair_cols$V1[i])) %&gt;% pull var2 &lt;- data2 %&gt;% select(all_of(pair_cols$V2[i])) %&gt;% pull nom_cor[i] = com_phi_f(var1, var2)} # Combine the nom_cor (corrlation value column) to the pair_cols data frame pair_cols &lt;- cbind(pair_cols, nom_cor) # Filter pairs having corrleation &gt;= threshold threshold = 0.20 pair_cols &lt;- pair_cols %&gt;% filter(abs(nom_cor) &gt;= threshold) # Connect the var_name of pairs having corr &gt; threshold high_cor_pair &lt;- igraph::graph_from_data_frame(pair_cols, directed = FALSE) # col_cluster &lt;- clusters(high_cor_pair) # Create a table include cluster_index and var_name group_var_dat &lt;- col_cluster$membership %&gt;% as.matrix() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;var_name&quot;)%&gt;% rename(group_index = &quot;.&quot;) %&gt;% select(group_index, var_name) # Split the var_name based on cluster index # Each cluster contains cluster index and variable (column) names # of highly correlated columns in the cluster my_cluster &lt;- split(group_var_dat, f=group_var_dat$group_index) my_cluster ## $`1` ## group_index var_name ## 1 1 X1 ## 4 1 X5 ## ## $`2` ## group_index var_name ## 2 2 X2 ## 3 2 X3 ## 5 2 X4 The below code chunk gives you tables of group indexes and names of variables in each group. In case you want to combine the result, which means you want to create a table with the names of variables in each group in one row, then you can do this: # Create nested tables depending on group index nest_data &lt;- group_var_dat %&gt;% group_by(group_index) %&gt;% nest() # Create a table that that take names (values) in each nested tibble and paste them together my_table &lt;- data.frame(matrix(ncol=1,nrow=0, dimnames=list(NULL, c(&quot;high_corrected_var&quot;)))) for (i in 1:dim(nest_data)[1]){ high_correted_var &lt;- (str_c(nest_data$data[[i]]%&gt;% unlist(use.names = F), collapse=&quot;, &quot;)) my_table &lt;- rbind(my_table, data.frame(high_correted_var))} Now you have a table with just one column, each row contains names of columns in each highly-correlated-columns cluster. my_table ## high_correted_var ## 1 X1, X5 ## 2 X2, X3, X4 7.6 Explain the steps in details colname &lt;- colnames(data2) pair_cols&lt;- combn(colname, 2) %&gt;% t %&gt;% as_tibble() pair_cols ## # A tibble: 10 × 2 ## V1 V2 ## &lt;chr&gt; &lt;chr&gt; ## 1 X1 X2 ## 2 X1 X3 ## 3 X1 X4 ## 4 X1 X5 ## 5 X2 X3 ## 6 X2 X4 ## 7 X2 X5 ## 8 X3 X4 ## 9 X3 X5 ## 10 X4 X5 com_phi_f &lt;-function(var1, var2){return(phi(table(var1, var2)))} # Create a vector that contain phi corr(V1, V2) for all of pairs nom_cor &lt;- c() for (i in 1:dim(pair_cols)[1]){ # get the values of the variable associated with variable #pair_cols$V1[row==i] and pair_cols$V2[row==i] var1 &lt;- data2 %&gt;% select(all_of(pair_cols$V1[i])) %&gt;% pull var2 &lt;- data2 %&gt;% select(all_of(pair_cols$V2[i])) %&gt;% pull nom_cor[i] = com_phi_f(var1, var2)} pair_cols &lt;- cbind(pair_cols, nom_cor) For doing the example, just choose a really small threshold = 0.20 threshold = 0.20 pair_cols &lt;- pair_cols %&gt;% filter(abs(nom_cor) &gt;= threshold) pair_cols ## V1 V2 nom_cor ## 1 X1 X5 0.22 ## 2 X2 X3 0.20 ## 3 X3 X4 -0.26 Now, we can create a list of highly correlated pairs using graph_from_data_frame high_cor_pair &lt;- igraph::graph_from_data_frame(pair_cols, directed = FALSE) high_cor_pair ## IGRAPH 67658ee UN-- 5 3 -- ## + attr: name (v/c), nom_cor (e/n) ## + edges from 67658ee (vertex names): ## [1] X1--X5 X2--X3 X3--X4 col_cluster &lt;- clusters(high_cor_pair) col_cluster ## $membership ## X1 X2 X3 X5 X4 ## 1 2 2 1 2 ## ## $csize ## [1] 2 3 ## ## $no ## [1] 2 group_var_dat &lt;- col_cluster$membership %&gt;% as.matrix() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;var_name&quot;) %&gt;% rename(group_index = &quot;.&quot;) %&gt;% select(group_index, var_name) group_var_dat ## group_index var_name ## 1 1 X1 ## 2 2 X2 ## 3 2 X3 ## 4 1 X5 ## 5 2 X4 my_cluster &lt;- split(group_var_dat, f=group_var_dat$group_index) my_cluster ## $`1` ## group_index var_name ## 1 1 X1 ## 4 1 X5 ## ## $`2` ## group_index var_name ## 2 2 X2 ## 3 2 X3 ## 5 2 X4 7.7 References [(https://stackoverflow.com/questions/39482364/group-of-highly-correlated-variables]((https://stackoverflow.com/questions/39482364/group-of-highly-correlated-variables) igraph - The network analysis package - webpage "],["relabel-study-names-into-a-numeric-sequence.html", "Section 8 Relabel study names into a numeric sequence 8.1 Introduction 8.2 Create data 8.3 Transform an arm-based data table to a study-based data table 8.4 Frequentist Network meta analysis 8.5 Arm base Network Meta Analysis using pcnetmeta package 8.6 References", " Section 8 Relabel study names into a numeric sequence 8.1 Introduction I have read a tutorial about how to use Bayesian network meta analysis. In that, to use the package, I have to relabel study names into a numeric sequence. So, this is the idea of the data that I want: suppressPackageStartupMessages(library(tidyverse)) ## # A tibble: 10 × 2 ## Study Study_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 B 2 ## 6 B 3 ## 7 B 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 8.2 Create data Study &lt;- c(&quot;E&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;D&quot; ) data &lt;- tibble(Study) data &lt;- data %&gt;% arrange(Study) # THIS STEP IS ESSENTIAL n_occur &lt;- data.frame(table(data$Study)) n_occur ## Var1 Freq ## 1 A 2 ## 2 B 3 ## 3 C 1 ## 4 D 2 ## 5 E 2 Stu_num_id &lt;- c() for (i in 1:dim(n_occur)[1]){ num_id &lt;- rep(i, times = n_occur$Freq[i]) Stu_num_id &lt;- Stu_num_id %&gt;% append(num_id) } Note: To make the study is appear correctly, you will need to arrange your studies based on alphabet order data &lt;- data %&gt;% cbind(Stu_num_id) data ## Study Stu_num_id ## 1 A 1 ## 2 A 1 ## 3 B 2 ## 4 B 2 ## 5 B 2 ## 6 C 3 ## 7 D 4 ## 8 D 4 ## 9 E 5 ## 10 E 5 8.2.1 What if we want to keep the order of Study names as they were Study &lt;- c(&quot;E&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;D&quot;) Study_num_id &lt;- c(1L, 1L, 2L, 2L, 2L, 3L, 4L, 4L, 5L, 5L) data &lt;- tibble(Study, Study_num_id) data ## # A tibble: 10 × 2 ## Study Study_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 B 2 ## 6 B 3 ## 7 B 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 data &lt;- data %&gt;% select(-c(&quot;Study_num_id&quot;)) n_occur &lt;- data.frame(table(data$Study)) n_occur ## Var1 Freq ## 1 A 2 ## 2 B 3 ## 3 C 1 ## 4 D 2 ## 5 E 2 I don’t think this is a clever way of doing this (especially with data having many studies). Study_name_unique &lt;- data %$% Study %&gt;% unique() Study_name_unique ## [1] &quot;E&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; Study &lt;- c() Stu_num_id &lt;- c() for (i in 1:dim(n_occur)[1]){ study &lt;- rep(Study_name_unique[i], times= n_occur$Freq[i]) Study &lt;- Study %&gt;% append(study) num_id &lt;- rep(i, times = n_occur$Freq[i]) Stu_num_id &lt;- Stu_num_id %&gt;% append(num_id) } Study_Studyid_dat &lt;- tibble(Study, Stu_num_id) Study_Studyid_dat ## # A tibble: 10 × 2 ## Study Stu_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 A 2 ## 6 B 3 ## 7 C 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 Now, we have a table with Study name and Study id with the original of Study name oder. If we have your original data with many more columns, what we need to do is just joining the two data tables. 8.3 Transform an arm-based data table to a study-based data table Treat &lt;- c(&quot;T&quot;, &quot;P&quot;, &quot;P&quot;, &quot;T&quot;, &quot;O&quot;, &quot;T&quot;, &quot;T&quot;, &quot;P&quot;, &quot;P&quot;, &quot;T&quot;) N &lt;- c(12, 23, 45, 78, 12, 2 , 4, 6, 8, 9) Total &lt;- c(222, 344, 222, 445, 224, 677, 345, 446, 234, 467) data &lt;- data %&gt;% cbind(Treat) %&gt;% cbind(N) %&gt;% cbind(Total)%&gt;% mutate(Treat = factor(Treat)) data ## Study Treat N Total ## 1 E T 12 222 ## 2 E P 23 344 ## 3 A P 45 222 ## 4 A T 78 445 ## 5 B O 12 224 ## 6 B T 2 677 ## 7 B T 4 345 ## 8 C P 6 446 ## 9 D P 8 234 ## 10 D T 9 467 data %&gt;% pivot_wider(names_from = Treat, values_from = c(N,Total)) ## # A tibble: 5 × 7 ## Study N_T N_P N_O Total_T Total_P Total_O ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 E &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 2 A &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 3 B &lt;dbl [2]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [2]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; ## 4 C &lt;NULL&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 5 D &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; 8.4 Frequentist Network meta analysis Reference: https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/netwma.html suppressPackageStartupMessages(library(dmetar)) DT::datatable(TherapyFormats) str(TherapyFormats) ## &#39;data.frame&#39;: 184 obs. of 8 variables: ## $ author : chr &quot;Ausbun, 1997&quot; &quot;Crable, 1986&quot; &quot;Thiede, 2011&quot; &quot;Bonertz, 2015&quot; ... ## $ TE : num 0.092 -0.675 -0.107 -0.09 -0.135 -0.217 0.103 -0.085 -0.052 -0.109 ... ## $ seTE : num 0.195 0.35 0.198 0.324 0.453 0.289 0.401 0.516 0.5 0.413 ... ## $ treat1 : chr &quot;ind&quot; &quot;ind&quot; &quot;ind&quot; &quot;ind&quot; ... ## $ treat2 : chr &quot;grp&quot; &quot;grp&quot; &quot;grp&quot; &quot;grp&quot; ... ## $ treat1.long: chr &quot;Individual&quot; &quot;Individual&quot; &quot;Individual&quot; &quot;Individual&quot; ... ## $ treat2.long: chr &quot;Group&quot; &quot;Group&quot; &quot;Group&quot; &quot;Group&quot; ... ## $ versus : chr &quot;ind vs grp&quot; &quot;ind vs grp&quot; &quot;ind vs grp&quot; &quot;ind vs grp&quot; ... TherapyFormats$treat1 %&gt;% unique() ## [1] &quot;ind&quot; &quot;grp&quot; &quot;gsh&quot; &quot;tel&quot; &quot;ush&quot; TherapyFormats %$% treat2 %&gt;% unique() ## [1] &quot;grp&quot; &quot;gsh&quot; &quot;tel&quot; &quot;wlc&quot; &quot;cau&quot; &quot;ush&quot; 8.5 Arm base Network Meta Analysis using pcnetmeta package Reference: https://pubmed.ncbi.nlm.nih.gov/28883783/ suppressPackageStartupMessages(library(&quot;pcnetmeta&quot;)) data(&quot;smoke&quot;) The columns: s.id: contains IDs for the 24 studies, t.id: labels the treatments included in each study r: the number of events n: the number of participants, respectively head(smoke) ## s.id t.id r n ## 1 1 1 9 140 ## 2 1 3 23 140 ## 3 1 4 10 138 ## 4 2 2 11 78 ## 5 2 3 12 85 ## 6 2 4 29 170 nma.networkplot(s.id, t.id, data = smoke, trtname = c(&quot;NC&quot;, &quot;SH&quot;, &quot;IC&quot;, &quot;GC&quot;)) 8.6 References Doing Meta-Analysis in R: A Hands-on Guide: Network Meta-Analysis Performing Arm-Based Network Meta-Analysis in R with the pcnetmeta Package "],["write-many-models-with-shortest-code-using-glue-and-rlang.html", "Section 9 Write many models with shortest code using glue and rlang 9.1 Introduction 9.2 Create a synthesis data 9.3 First way: using glue::glue, parse and eval 9.4 Second way: using tidy evaluation operator 9.5 Other tips 9.6 References", " Section 9 Write many models with shortest code using glue and rlang 9.1 Introduction In case you want to fit many models, even if each is a really simple model, say linear regression, \\(model_i \\leftarrow lm(Y_i\\sim X1+X2+X3+X4)\\), for \\(i=\\overline{1,30}\\). To fit these 30 models, you may have to write 30 lines unnecessarily long and error-prone with copy and paste. In this section, I will briefly introduce two ways that save you time and make your code look nicer and more accessible to debug: I will give just a small example that we want to fit 3 models \\(model_i \\leftarrow lm(Y_i\\sim X1+X2+X3+X4, data = syn\\space data)\\), for \\(i=\\overline{1,3}\\). But the idea for writing more models is just the same. This example may not give you a strong impression when I just fit linear regression models, but believe me, it will be a different story when we have more complicated models. This section includes the following: Create a synthesis of data. Way 1 for writing many models: using glue::glue, parse, and eval. Way 2 for writing many models: using rlang tidy evaluation operator. 9.2 Create a synthesis data suppressPackageStartupMessages(library(tidyverse)) set.seed(386827) n = 100 # sample size # Synthesis inputs X1 &lt;- rnorm(n, mean = 10, sd = 3) X2 &lt;- rnorm(n, mean = 16, sd = 2) X3 &lt;- rbinom(n, 1, 0.4) X4 &lt;- rbinom(n, 1, 0.5) # epsilons eps1 &lt;- rnorm(n, 0, 1) eps2 &lt;- rnorm(n, 0, 0.5) eps3 &lt;- eps2 # Create synthesis output Y1 &lt;- 3*X1 + 2*X2 + 8*X3 + 5*X4 + eps1 Y2 &lt;- 15*X1 + 0*X2 + 5*X3 + 3*X4 + eps2 Y3 &lt;- 1*X1 + 12* X2 + 2*X3 + 4*X4 + eps3 # Synthesis data syn_dat &lt;- tibble::tibble(X1, X2, X3, X4, Y1, Y2, Y3) head(syn_dat) ## # A tibble: 6 × 7 ## X1 X2 X3 X4 Y1 Y2 Y3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11.7 14.0 1 0 74.0 182. 182. ## 2 12.1 15.5 1 1 81.1 191. 204. ## 3 6.70 16.2 1 1 65.3 108. 207. ## 4 16.4 16.1 1 1 94.7 254. 215. ## 5 9.75 18.3 0 0 64.7 147. 230. ## 6 8.89 14.7 0 0 57.5 134. 186. To fit the three above linear models, you will have to write: (model1 &lt;- lm(Y1~X1+X2+X3+X4, data=syn_dat)) ## ## Call: ## lm(formula = Y1 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## 0.583 2.987 1.959 8.151 5.070 (model2 &lt;- lm(Y2~X1+X2+X3+X4, data=syn_dat)) ## ## Call: ## lm(formula = Y2 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.0407353 15.0036299 -0.0001834 4.9775274 3.0010207 (model3 &lt;- lm(Y3~X1+X2+X3+X4, data=syn_dat)) ## ## Call: ## lm(formula = Y3 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.04074 1.00363 11.99982 1.97753 4.00102 9.3 First way: using glue::glue, parse and eval We will not see much difference with three models. However, this way saves you lots of time if you have 30 models to write. out &lt;- c(&quot;Y1&quot;, &quot;Y2&quot;, &quot;Y3&quot;) model &lt;- c(&quot;model1&quot;, &quot;model2&quot;, &quot;model3&quot;) num_model = length(model) glue::glue(&#39;{model[1:num_model]} &lt;- lm({out[1:num_model]}~X1+X2+X3+X4, data=syn_dat)&#39;) %&gt;% parse(text = .) %&gt;% eval(envir = globalenv()) When we finish the above code chunk, we will have the three needed models. Now, we can print them. model1; model2; model3 ## ## Call: ## lm(formula = Y1 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## 0.583 2.987 1.959 8.151 5.070 ## ## Call: ## lm(formula = Y2 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.0407353 15.0036299 -0.0001834 4.9775274 3.0010207 ## ## Call: ## lm(formula = Y3 ~ X1 + X2 + X3 + X4, data = syn_dat) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.04074 1.00363 11.99982 1.97753 4.00102 9.4 Second way: using tidy evaluation operator For more information about rlang- tidy evaluation operator, read this awesome introduction for an awesome package rlang-0-4-0. This way is the best when we have more complicated models. fit_many_model &lt;- function(data, out){ # out: output names model &lt;- lm({{out}}~X1+X2+X3+X4, data=data) return(model) } So now we have our models # Or you can use # (model1 &lt;- syn_dat %&gt;% fit_many_regression(Y1)) (model1 &lt;- fit_many_model(syn_dat, Y1)) ## ## Call: ## lm(formula = { ## { ## out ## } ## } ~ X1 + X2 + X3 + X4, data = data) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## 0.583 2.987 1.959 8.151 5.070 (model2 &lt;- fit_many_model(syn_dat, Y2)) ## ## Call: ## lm(formula = { ## { ## out ## } ## } ~ X1 + X2 + X3 + X4, data = data) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.0407353 15.0036299 -0.0001834 4.9775274 3.0010207 (model3 &lt;- fit_many_model(syn_dat, Y3)) ## ## Call: ## lm(formula = { ## { ## out ## } ## } ~ X1 + X2 + X3 + X4, data = data) ## ## Coefficients: ## (Intercept) X1 X2 X3 X4 ## -0.04074 1.00363 11.99982 1.97753 4.00102 9.5 Other tips We can write many lines of code using cat, paste the result in your R_script/Rmarkdown-code chunk, and then run them. For example, this is how you can have three linear regression models put in three different sections and code chunks in R Markdown. Add more in i_list then we have more models. i_list &lt;- c(1,2,3) for(i in i_list) { cat(&quot;\\n&quot;) cat(&quot;### &quot;, &quot;model&quot;, i,&quot;\\n&quot;,sep=&quot;&quot;) cat(&quot;```{r}&quot;,&quot;\\n&quot;,sep=&quot;&quot;) cat(&quot;model&quot;,i , &quot;&lt;-fit_many_model(syn_dat, Y&quot;, i, &quot;)\\n&quot;,sep=&quot;&quot;) cat(&quot;```&quot;,&quot;\\n&quot;,sep=&quot;&quot;) } ## ## ### model1 ## ```{r} ## model1&lt;-fit_many_model(syn_dat, Y1) ## ``` ## ## ### model2 ## ```{r} ## model2&lt;-fit_many_model(syn_dat, Y2) ## ``` ## ## ### model3 ## ```{r} ## model3&lt;-fit_many_model(syn_dat, Y3) ## ``` 9.6 References Main reference _ rlang-0-4-0/ Introduction to tidyeval Tidy eval in R: A simple example https://www.youtube.com/watch?v=9v9-EpTuwk0 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
