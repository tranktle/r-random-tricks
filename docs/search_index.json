[["index.html", "Tran Le _ Random R tricks Section 1 Introduction", " Tran Le _ Random R tricks Tran Le 04-01-2022 Updated:2023-09-29 Section 1 Introduction This book-down file is where I keep the observations/tricks I got while using R. I also use this file to write some cheat sheets for later quick reference. Sometimes, I write something when my friends ask me a question. I believe explaining to someone is an excellent way to help me understand and learn better. These are my LinkedIn and GitHub pages. Please connect so that we can learn from each other. Happy studying ! "],["github-cheatsheet.html", "Section 2 Github-Cheatsheet 2.1 Introduction 2.2 Connecting an existing Rstudio project to Github. 2.3 Integrate Rstudio with an existing project on Github 2.4 How to post your Bookdown file to Github 2.5 Some most common git commands. 2.6 References", " Section 2 Github-Cheatsheet 2.1 Introduction This is a cheat sheet for using Github with R, including: Connecting an existing Rstudio project to Github. Integrate Rstudio with an existing project on Github. How to post your Bookdown file to Github. Side note: Some most common git commands. I have learned about Git and Github from here and from GitHub Docs. The content of this cheat sheet mainly gotten from here. 2.2 Connecting an existing Rstudio project to Github. When you have an R project on your computer and want to post it on your GitHub page one day, this part can help you do that. Step 1: Creating our local git repository In Rstudio , go to Tools \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Project Setup \\(\\rightarrow\\) This will bring you to Project Options panel. In this panel, in Version control system, choose Git , click OK. Then you can choose to use Git tab or Git commands to process steps after creating repository on GitHub. Step 2: Creating repository on GitHub. In this step, skip all of the check boxes for Add a README file, Add. gitignore, Choose a license. Click Create repository. After this step, you will have a Quick Setup screen that have some Git commands that you could use, such as: To create a new repository on the command line git init git add README.md git commit -m “first commit” git branch -M main git remote add origin git@github.com:your_GitHub_account_name/your_repository_name.git git push -u origin main To push an existing repository from the command line git remote add origin git@github.com:your_GitHub_account_name/your_repository_name.git git branch -M main git push -u origin main Step3: Connect local repository to GitHub Go to Terminal tab, paste the commandS in (2b) to connect and push your R project to your GitHub repository. 2.3 Integrate Rstudio with an existing project on Github Step 1: Clone your repository to create a Rstudio project From your GitHub repository -&gt; click on Code -&gt; copy the content clone from SSH, In Rstudio -&gt; New Project -&gt; Version Control -&gt; Git -&gt; In the repository URL, paste the link you got above (the copied SSH link). In the Project directory name, type the name of the project that you want to use (recommend to use the same name with your GitHub repository) In the Create project as a subdirectory of: browse the place you want to keep the project on your computer. Then click “Create Project”. After this step, you have a Rproject that is cloned from your Github repository. Step 2: modify your Rproject and push it back to your GitHub repository. (Optional) Modify the Rproject/Rbook-down …, build your book-down file,… (Optional) Update the gitignore file if you have some files/folders that you don’t want to push into your GitHub page. Click on Git, check the changes (check boxes) that you want to commit, input the Commit message, then click Commit. Click on Push to push your project to the Github page. 2.4 How to post your Bookdown file to Github Create a book-down project with the format gitbook. After that, init the git init in the terminal, commit all of the files, Go to output.yml to comment the bookdown:pdf_book and bookdown::epub_book: default so that we only create the gitbook file when we init. Go to the bookdown.yml file; we change where the output will be placed. Change from this: To this: delete_merged_file: true language:     ui:   chapter_name: “Chapter “ delete_merged_file: true output_dir: “docs” language:    ui:     chapter_name: “Chapter “ Go to the .gitignor file, and add \\(\\_\\)bookdown_files in the file. Git add docs/, commit, push all things on github. In GitHub, on Settings, go to Pages =&gt; GitHub Pages =&gt; change it to main, /docs . Then the link to your book is found in Your site is published at: 2.5 Some most common git commands. To use these commands on RStudio, you will need to come to Terminal and type the commands. - git config –global user.name “[name]”: sets author name. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD - git config –global user.email “your_email@example.com”: sets author email id. ======= - git config –global user.email “[email address]”: sets author email id. &gt;&gt;&gt;&gt;&gt;&gt;&gt; a0f7d01cfa45f6a4da7bbf9814f0db459eaf7a20 - git init [repository_name]: start new repository. - git clone [url]: obtains a repository from an existing URL. - git status: lists all the files that have to be committed. - git commit -am [your_commit_message]: commits any files you’ve changed or added. - git push -u origin main: sends the committed changes of origin branch to your remote repository. 2.6 References Git and GitHub for Beginners - Crash Course - Youtube Git Commands (taken from the above tutorial) How to intall git Generating a new SSH key and adding it to the ssh-agent Youtube Integrating RStudio with a new or existing project on GitHub (CC120) "],["r-resources-from-absolute-beginners-to-more-advance.html", "Section 3 R resources from absolute beginners to more advance 3.1 Introduction 3.2 For absolute beginners. 3.3 R graphs galleries 3.4 Some R excellent books", " Section 3 R resources from absolute beginners to more advance 3.1 Introduction It may not be a good idea to put this section here. But today, I went to the Mississippi Public Health Association ’s World Field Epidemiology Day Workshop. I meet some new friends there who study Epidemiology that want to learn R. I think I need to share these really good and free  resources. The resources will be listed from the absolute beginner to more advanced levels. If you have any suggestions or want to add more resources about the topic that you want to learn, please let me know (here is my LinkedIn account). I will update and correct this according to that. 3.2 For absolute beginners. MarinStatsLectures-R Programming &amp; Statistics was the first teacher that taught me the first steps in R. This Chanel contains many topics that you can learn. This is the first series that you need to watch if you know nothing about R. This will teach you how to install R, R studio, install R packages, import your data… Then you can explore other playlists from him if you are interested. 3.3 R graphs galleries I have seen you people discuss a lot about how to use graphs. This link, https://r-graph-gallery.com/ will give you a quick tutorial on creating those plots. Please click on the plot you want, for example, Barplot, then it will take you to the page with many bar plots and instructions. This is the link I got after choosing the most basic bar plot from the main page: [https://r-graph-gallery.com/218-basic-barplots-with-ggplot2.html]. Another library we can use to create plots is Plotly. Here is the link to the Plotly gallery: https://plotly.com/r/. Similarly, click the plot you want to make and have the code on your hands. (I personally use ggplot2 more frequently than Plotly). 3.4 Some R excellent books R for Data Science is the book everyone who studies R needs to read. It teaches you how to do Data Visualization, Data Wrangling, and many more. We also have cheat sheets that are associated with this book. You can download them from here. Advanced R, as its name says about itself, is an advanced R book. I have not read these two books, but I think they may be helpful for you. R for Epidemiology and R for applied epidemiology and public health "],["problems-when-using-dplyrfull_join.html", "Section 4 Problems when using dplyr::full_join 4.1 Introduction 4.2 Using dplyr::full_join 4.3 Using powerjoin::power_full_join 4.4 What if we have conflict data sets 4.5 References", " Section 4 Problems when using dplyr::full_join library(powerjoin) ## Warning: package &#39;powerjoin&#39; was built under R version 4.3.1 library(tidyverse) ## Warning: package &#39;tidyverse&#39; was built under R version 4.3.1 ## Warning: package &#39;purrr&#39; was built under R version 4.3.1 ## ── Attaching core tidyverse packages ───────────────────────────────────────────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.2 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ lubridate 1.9.2 ✔ tibble 3.2.1 ## ✔ purrr 1.0.2 ✔ tidyr 1.3.0 ## ── Conflicts ─────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors 4.1 Introduction This part will explore some problems that we may cope with when using dplyr::full_join, and it is why powerchoice::power_full_join may come in handy. Assume that we have two people: name = John, age = 30, sex = “M”, treatment = NA (we don’t know John’s treatment) name = Marry, age = 45, sex = “F”, treatment = “A” However, we have multiple data sets that contain incomplete information about these two people. Let us consider the data that we have and the problems that we might have to cope with while trying to get data that contains as much information as possible from these two people by joining our available data sets. 4.2 Using dplyr::full_join First, let us consider the below data set. With this data set, we will get the same result while using dfs %&gt;% reduce(full_join) and dfs %&gt;% reduce(full_join, by= name). We do not see any problem here, and we collect all the information from our available data sets. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;) ) dfs %&gt;% reduce(full_join) ## Joining with `by = join_by(name)` ## Joining with `by = join_by(name)` ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A dfs %&gt;% reduce(full_join, by=&quot;name&quot;) ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A However, let us consider when our dfs list has one more row (the fourth row) with the name and age of Mary. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45) ) The full_join without identifying the key by=\"name\" may think that there are two people with the same name, “Mary”. dfs %&gt;% reduce(full_join) ## Joining with `by = join_by(name)` ## Joining with `by = join_by(name)` ## Joining with `by = join_by(name, age)` ## # A tibble: 3 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A ## 3 Mary 45 &lt;NA&gt; &lt;NA&gt; The full_join with identifying the key by=\"name\"creates extra columns when we have duplicated column names dfs %&gt;% reduce(full_join, by = &quot;name&quot;) ## # A tibble: 2 × 5 ## name age.x sex treatment age.y ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John 30 M &lt;NA&gt; NA ## 2 Mary NA F A 45 We may think about how to delete these extra columns by doing like below code chunk. However, by doing this, we lost the information about Mary’s age (which was available in the age.y column above). dfs %&gt;% reduce(full_join, by = &quot;name&quot;, suffix = c(&quot;&quot;, &quot;.y&quot;)) %&gt;% select(-ends_with(&quot;.y&quot;)) ## # A tibble: 2 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A 4.3 Using powerjoin::power_full_join Solve the problem using powerjoin. Let’s consider the dfs list with one more row. The problems we have when using dplyr::full_join and how powerjoin::power_full_join can be helpful. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45), fifth = tibble(name = &quot;Mary&quot;, sex = &quot;F&quot;) ) dfs %&gt;% reduce(full_join) ## Joining with `by = join_by(name)` ## Joining with `by = join_by(name)` ## Joining with `by = join_by(name, age)` ## Joining with `by = join_by(name, sex)` ## # A tibble: 3 × 4 ## name age sex treatment ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; ## 2 Mary NA F A ## 3 Mary 45 &lt;NA&gt; &lt;NA&gt; dfs %&gt;% reduce(full_join, by = &quot;name&quot;) ## # A tibble: 2 × 6 ## name age.x sex.x treatment age.y sex.y ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 John 30 M &lt;NA&gt; NA &lt;NA&gt; ## 2 Mary NA F A 45 F The powerjoin package helps us collect all available information. dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_xy) ## # A tibble: 2 × 4 ## name treatment age sex ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 John &lt;NA&gt; 30 M ## 2 Mary A 45 F 4.4 What if we have conflict data sets Now, consider that we have two data sets for Mary that have different values for “age” (the fourth and fifth), with ages equal to 45 and 65, respectively. dfs &lt;- list( first = tibble(name = &quot;John&quot;, age = 30), second = tibble(name = c(&quot;John&quot;, &quot;Mary&quot;), sex = c(&quot;M&quot;, &quot;F&quot;)), third = tibble(name = &quot;Mary&quot;, treatment = &quot;A&quot;), fourth = tibble(name = &quot;Mary&quot;, age = 45), fifth = tibble(name = &quot;Mary&quot;, age = 65) ) Then the argument conflict = coalesce_xy will take the first available value (age = 45), while conflict = coalesce_yx will take the second available value (age = 65). dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_xy) ## # A tibble: 2 × 4 ## name sex treatment age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John M &lt;NA&gt; 30 ## 2 Mary F A 45 dfs %&gt;% power_full_join(by= &quot;name&quot;, conflict = coalesce_yx) ## # A tibble: 2 × 4 ## name sex treatment age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 John M &lt;NA&gt; 30 ## 2 Mary F A 65 4.5 References https://github.com/moodymudskipper/powerjoin "],["load-and-write-to-an-excel-sheet.html", "Section 5 Load and write to an excel sheet 5.1 Introduction 5.2 Code", " Section 5 Load and write to an excel sheet 5.1 Introduction This section can be considered as a cheat sheet for loading and writing to an excel sheet. 5.2 Code library(openxlsx) # Put in HTML result table source(&quot;utilities.R&quot;) wb &lt;- loadWorkbook(&quot;location/Your_Excel_File_Name.xlsx&quot;) sheetname =&quot;Sheet_name_that_you_want_to_write_on&quot; # You can write many table/content that you want in a sheet using writeData writeData(wb, sheetname, table_you_want_to_write_on, startRow = 11, startCol = &quot;F&quot;, colNames = F) # Open a temporary version to check if we have the correct way that we want our data to be written in the Excel sheet file. openXL(wb) # Then you can write the file with new/old name. saveWorkbook(wb = wb, file = &quot;location/Your_New/Old_Excel_File_Name.xlsx&quot;,overwrite = T) "],["replace-values-by-nasa-specfic-value.html", "Section 6 Replace Values by Nas/A specfic value 6.1 Introduction 6.2 replace_with_na(): replace specific value(s) at in specific columns by NAs. 6.3 replace_with_na_all() Replaces some values by NA for all columns. 6.4 replace_with_na_at(): replaces some chosen values in a chosen set of columns by NAs. 6.5 replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NA.", " Section 6 Replace Values by Nas/A specfic value 6.1 Introduction We will explore some cases in which we can quickly change some values to NAs. Some useful commands (from the library naniar) include: replace_with_na(): replace specific value(s) at in specific columns by NAs. replace_with_na_all(): Replaces some values by NAs for all columns. replace_with_na_at(): Replaces some chosen values in a chosen set of columns by NAs. replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NAs. suppressPackageStartupMessages(library(tidyverse)) library(naniar) Let’s first create a data example. You can see that the data_example that we create here represents what we would expect if we have a character value in a numerical column if we read data from a CSV file. For example, column y is a column with numerical values, but since there is NR (NR means not reported) in the column, R will think it is a character column when we read the data. data_example&lt;- tribble( ~name, ~x, ~y, ~z, ~t, &quot;Mr.A&quot;, &quot;a&quot;, &quot;2&quot;, &quot;3.6&quot;, &quot;na&quot;, &quot;Mr.B&quot;, &quot;b&quot;, &quot;1&quot;, &quot;.&quot;, &quot;2.1&quot;, &quot;Ms. C&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;10&quot;, &quot;3.4&quot;, &quot;Ms. D&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;NR&quot;, &quot;1&quot;) data_example ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C NR NR 10 3.4 ## 4 Ms. D NR NR NR 1 6.2 replace_with_na(): replace specific value(s) at in specific columns by NAs. replace_with_na replaces a list of values in a list of columns by Na, where each column has different values that we want to replace. We may need to use this in case a value should be converted to NA in a column but not in another column. For example, we want to convert NR to NA in column x, but do not want to do so with column z (with column z, we only want to convert “.” to NAs but keep NR as it is). data_example %&gt;% naniar::replace_with_na(replace = list(x = c(&quot;NR&quot;), y = c(&quot;NR&quot;), z = c(&quot;.&quot;))) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; NR 1 6.3 replace_with_na_all() Replaces some values by NA for all columns. Here, we want to replace a value “NR” by NAs. data_example %&gt;% replace_with_na_all(., condition = ~.x == &quot;NR&quot;) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 In case we want to replace many more values by NA, we can use \\(%in%\\) as below data_example %&gt;% replace_with_na_all(., condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 6.4 replace_with_na_at(): replaces some chosen values in a chosen set of columns by NAs. Replace “NR” and “.” at columns x and y with NAs: data_example %&gt;% replace_with_na_at(.var=c(&quot;x&quot;, &quot;y&quot;), condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 . 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; NR 1 6.5 replace_with_na_if(): Replaces some values on some columns with conditions (is.numeric, is.character) by NA. data_example %&gt;% replace_with_na_if(is_character, condition = ~.x %in% c(&quot;NR&quot;, &quot;.&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mr.A a 2 3.6 na ## 2 Mr.B b 1 &lt;NA&gt; 2.1 ## 3 Ms. C &lt;NA&gt; &lt;NA&gt; 10 3.4 ## 4 Ms. D &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ## A helpfull observation using mutate_at and replace Besides of replace values by Na. We also can replace specific values by a value in some selected columns. One example can be data_example %&gt;% mutate_at(c(&quot;name&quot;), ~replace(., .%in% c(&quot;Mr.A&quot;, &quot;Mr.B&quot;), &quot;The AB&quot;)) ## # A tibble: 4 × 5 ## name x y z t ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 The AB a 2 3.6 na ## 2 The AB b 1 . 2.1 ## 3 Ms. C NR NR 10 3.4 ## 4 Ms. D NR NR NR 1 ======= &gt;&gt;&gt;&gt;&gt;&gt;&gt; 56eeb42d87bc29311ec57c37bae5be9a4b59edac ## References https://www.rdocumentation.org/packages/naniar/versions/0.6.1/topics/replace_with_na "],["find-group-of-highly-correlated-columns.html", "Section 7 Find group of highly correlated columns 7.1 Introduction 7.2 Data set and the code to get the result 7.3 Explain the code in details 7.4 Deal with nominal-nominal variables 7.5 Here is the code to get group of highly correlated columns 7.6 Explain the steps in details", " Section 7 Find group of highly correlated columns 7.1 Introduction Here, we will explore how to find groups of highly correlated columns. Each group contains columns having a correlation higher than a fixed chosen threshold. We will first give a simple data set, then give the code and the result we get. After all, we will explore how the code works. This example based on the question and answer that I got from stackoverflow.com. Some of the functions have been updated since the package is updated at the time I wrote this section (2022). Besides exploring how to find groups of highly correlated numerical columns, I also do the same with (binary) nominal columns. However, since no command helps compute the correlation matrix with a numerical column, we will need to process this step slightly differently than the above example. This way can be applied if we want to find other kinds of groups of highly correlated variables, such as numeric-numeric and numeric-ordinal,… 7.2 Data set and the code to get the result suppressPackageStartupMessages(library(tidyverse)) suppressPackageStartupMessages(library(igraph)) suppressPackageStartupMessages(library(DescTools)) suppressPackageStartupMessages(library(psych)) data1 &lt;- structure(list(A = c(1L, 2L, 5L, 4L, 366L, 65L, 43L, 456L, 876L, 78L, 687L, 378L, 378L, 34L, 53L, 43L), B = c(2L, 2L, 5L, 4L, 366L, 65L, 43L, 456L, 876L, 78L, 687L, 378L, 378L, 34L, 53L, 41L), C = c(10L, 20L, 10L, 20L, 10L, 20L, 1L, 0L, 1L, 2010L,20L, 10L, 10L, 10L, 10L, 10L), D = c(2L, 10L, 31L, 2L, 2L, 5L, 2L, 5L, 1L, 52L, 1L, 2L, 52L, 6L, 2L, 1L), E = c(4L, 10L, 31L, 2L, 2L, 5L, 2L, 5L, 1L, 52L, 1L, 2L, 52L, 6L, 2L, 3L)), .Names = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), class = &quot;data.frame&quot;, row.names = c(NA,-16L)) Here is the code that we can use to get the result # Compute correlation of columns in data1 using pearson var.corelation &lt;- cor(as.matrix(data1), method=&quot;pearson&quot;) # prevent duplicated pairs var.corelation &lt;- var.corelation*lower.tri(var.corelation) # Filter pairs having correlation &gt; threshold check.corelation &lt;- which(abs(var.corelation)&gt;0.62, arr.ind=TRUE) graph.cor &lt;- graph_from_data_frame(check.corelation, directed = FALSE) # groups.cor &lt;- split(unique(as.vector(check.corelation)), clusters(graph.cor)$membership) # Get the row name of highly correlated groups lapply(groups.cor,FUN=function(list.cor){rownames(var.corelation)[list.cor]}) ## $`1` ## [1] &quot;B&quot; &quot;A&quot; ## ## $`2` ## [1] &quot;D&quot; &quot;E&quot; &quot;C&quot; If our data has a small number of columns, we can plot groups of highly correlated columns. The below graph gives indexed highly correlated clusters. plot(graph.cor, vertex.label = V(graph.cor)$name) 7.3 Explain the code in details First, notice that our data only contains numeric columns; we can compute a correlation matrix using Pearson correlation. var.corelation &lt;- cor(as.matrix(data1), method=&quot;pearson&quot;) var.corelation ## A B C D E ## A 1.0000000 0.9999978 -0.1385469 -0.1125711 -0.1242381 ## B 0.9999978 1.0000000 -0.1384694 -0.1124062 -0.1240949 ## C -0.1385469 -0.1384694 1.0000000 0.6212136 0.6220380 ## D -0.1125711 -0.1124062 0.6212136 1.0000000 0.9992690 ## E -0.1242381 -0.1240949 0.6220380 0.9992690 1.0000000 Since the correlation matrix is symmetric through the diagonal and the values on the diagonal are equal to 1, we just need to keep the values in the lower diagonal. lower.tri(var.corelation) ## [,1] [,2] [,3] [,4] [,5] ## [1,] FALSE FALSE FALSE FALSE FALSE ## [2,] TRUE FALSE FALSE FALSE FALSE ## [3,] TRUE TRUE FALSE FALSE FALSE ## [4,] TRUE TRUE TRUE FALSE FALSE ## [5,] TRUE TRUE TRUE TRUE FALSE var.corelation &lt;- var.corelation*lower.tri(var.corelation)- var.corelation With this example, we only filter columns with a correlation &gt; 0.62. The result below shows us the location row and columns of highly correlated pairs. For example, The first one is (row 2, column 1) associated with (B, A) is a pair of columns having correlation &gt; threshold, etc. threshold = 0.62 check_corelation &lt;- which(abs(var.corelation)&gt;0.62, arr.ind=TRUE) check_corelation ## row col ## A 1 1 ## A 1 2 ## B 2 2 ## C 3 3 ## C 3 4 ## D 4 4 ## C 3 5 ## D 4 5 ## E 5 5 graph.cor &lt;- graph_from_data_frame(check.corelation, directed = FALSE) graph.cor ## IGRAPH 66f2f02 UN-- 5 4 -- ## + attr: name (v/c) ## + edges from 66f2f02 (vertex names): ## [1] 2--1 4--3 5--3 4--5 Now, we will consider the clusters’ membership used to split our data. From the membership, the first row is the indexes of columns, and the second row is the index of the cluster that those columns belong to. We see that column with indexes 2 and 1 (columns B and A) is in cluster 1, and columns with indexes 4, 5, and 3 (columns D, E, and C) are in cluster 2. components(graph.cor) ## $membership ## 2 4 5 1 3 ## 1 2 2 1 2 ## ## $csize ## [1] 2 3 ## ## $no ## [1] 2 So, now we split the column indexes into cluster unique(as.vector(check.corelation)) ## [1] 2 4 5 1 3 groups.cor &lt;- split(unique(as.vector(check.corelation)), components(graph.cor)$membership) groups.cor ## $`1` ## [1] 2 1 ## ## $`2` ## [1] 4 5 3 And get the column names of the columns in each cluster. lapply(groups.cor,FUN=function(list.cor){rownames(var.corelation)[list.cor]}) ## $`1` ## [1] &quot;B&quot; &quot;A&quot; ## ## $`2` ## [1] &quot;D&quot; &quot;E&quot; &quot;C&quot; 7.4 Deal with nominal-nominal variables set.seed(365263) X1 &lt;- sample(c(&quot;A&quot;, &quot;B&quot;), size = 16, replace = TRUE) X2 &lt;- sample(c(&quot;E&quot;, &quot;H&quot; ), size = 16, replace = TRUE) X3 &lt;- sample(c(&quot;X&quot;, &quot;Y&quot;), size = 16, replace = TRUE) X4 &lt;- sample(c(&quot;L&quot;, &quot;M&quot;), size = 16, replace = TRUE) X5 &lt;- sample(c(&quot;K&quot;, &quot;L&quot;), size = 16, replace = TRUE) data2 &lt;- tibble(X1, X2, X3, X4, X5) head(data2) ## # A tibble: 6 × 5 ## X1 X2 X3 X4 X5 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B H X M L ## 2 B H Y M K ## 3 A H Y L L ## 4 B E Y L L ## 5 B E Y L L ## 6 B H X M L 7.5 Here is the code to get group of highly correlated columns colname &lt;- colnames(data2) pair_cols&lt;- combn(colname, 2) %&gt;% t %&gt;% as_tibble() ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. ## ℹ Using compatibility `.name_repair`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. com_phi_f &lt;-function(var1, var2){return(phi(table(var1, var2)))} # Create a vector that contain phi corr(V1, V2) for all of pairs nom_cor &lt;- c() for (i in 1:dim(pair_cols)[1]){ # get the values of the variable associated with variable #pair_cols$V1[row==i] and pair_cols$V2[row==i] var1 &lt;- data2 %&gt;% select(all_of(pair_cols$V1[i])) %&gt;% pull var2 &lt;- data2 %&gt;% select(all_of(pair_cols$V2[i])) %&gt;% pull nom_cor[i] = com_phi_f(var1, var2)} # Combine the nom_cor (corrlation value column) to the pair_cols data frame pair_cols &lt;- cbind(pair_cols, nom_cor) # Filter pairs having corrleation &gt;= threshold threshold = 0.20 pair_cols &lt;- pair_cols %&gt;% filter(abs(nom_cor) &gt;= threshold) # Connect the var_name of pairs having corr &gt; threshold high_cor_pair &lt;- igraph::graph_from_data_frame(pair_cols, directed = FALSE) # col_cluster &lt;- clusters(high_cor_pair) # Create a table include cluster_index and var_name group_var_dat &lt;- col_cluster$membership %&gt;% as.matrix() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;var_name&quot;)%&gt;% rename(group_index = &quot;.&quot;) %&gt;% select(group_index, var_name) # Split the var_name based on cluster index # Each cluster contains cluster index and variable (column) names # of highly correlated columns in the cluster my_cluster &lt;- split(group_var_dat, f=group_var_dat$group_index) my_cluster ## $`1` ## group_index var_name ## 1 1 X1 ## 4 1 X5 ## ## $`2` ## group_index var_name ## 2 2 X2 ## 3 2 X3 ## 5 2 X4 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD The below code chunk gives you tables of group indexes and names of variables in each group. In case you want to combine the result, which means you want to create a table with the names of variables in each group in one row, then you can do this: # Create nested tables depending on group index nest_data &lt;- group_var_dat %&gt;% group_by(group_index) %&gt;% nest() # Create a table that that take names (values) in each nested tibble and paste them together my_table &lt;- data.frame(matrix(ncol=1,nrow=0, dimnames=list(NULL, c(&quot;high_corrected_var&quot;)))) for (i in 1:dim(nest_data)[1]){ high_correted_var &lt;- (str_c(nest_data$data[[i]]%&gt;% unlist(use.names = F), collapse=&quot;, &quot;)) my_table &lt;- rbind(my_table, data.frame(high_correted_var))} Now you have a table with just one column, each row contains names of columns in each highly-correlated-columns cluster. my_table ## high_correted_var ## 1 X1, X5 ## 2 X2, X3, X4 ======= 56eeb42d87bc29311ec57c37bae5be9a4b59edac 7.6 Explain the steps in details colname &lt;- colnames(data2) pair_cols&lt;- combn(colname, 2) %&gt;% t %&gt;% as_tibble() pair_cols ## # A tibble: 10 × 2 ## V1 V2 ## &lt;chr&gt; &lt;chr&gt; ## 1 X1 X2 ## 2 X1 X3 ## 3 X1 X4 ## 4 X1 X5 ## 5 X2 X3 ## 6 X2 X4 ## 7 X2 X5 ## 8 X3 X4 ## 9 X3 X5 ## 10 X4 X5 com_phi_f &lt;-function(var1, var2){return(phi(table(var1, var2)))} # Create a vector that contain phi corr(V1, V2) for all of pairs nom_cor &lt;- c() for (i in 1:dim(pair_cols)[1]){ # get the values of the variable associated with variable #pair_cols$V1[row==i] and pair_cols$V2[row==i] var1 &lt;- data2 %&gt;% select(all_of(pair_cols$V1[i])) %&gt;% pull var2 &lt;- data2 %&gt;% select(all_of(pair_cols$V2[i])) %&gt;% pull nom_cor[i] = com_phi_f(var1, var2)} pair_cols &lt;- cbind(pair_cols, nom_cor) For doing the example, just choose a really small threshold = 0.20 threshold = 0.20 pair_cols &lt;- pair_cols %&gt;% filter(abs(nom_cor) &gt;= threshold) pair_cols ## V1 V2 nom_cor ## 1 X1 X5 0.22 ## 2 X2 X3 0.20 ## 3 X3 X4 -0.26 Now, we can create a list of highly correlated pairs using graph_from_data_frame high_cor_pair &lt;- igraph::graph_from_data_frame(pair_cols, directed = FALSE) high_cor_pair ## IGRAPH 6777688 UN-- 5 3 -- ## + attr: name (v/c), nom_cor (e/n) ## + edges from 6777688 (vertex names): ## [1] X1--X5 X2--X3 X3--X4 col_cluster &lt;- clusters(high_cor_pair) col_cluster ## $membership ## X1 X2 X3 X5 X4 ## 1 2 2 1 2 ## ## $csize ## [1] 2 3 ## ## $no ## [1] 2 group_var_dat &lt;- col_cluster$membership %&gt;% as.matrix() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;var_name&quot;) %&gt;% rename(group_index = &quot;.&quot;) %&gt;% select(group_index, var_name) group_var_dat ## group_index var_name ## 1 1 X1 ## 2 2 X2 ## 3 2 X3 ## 4 1 X5 ## 5 2 X4 my_cluster &lt;- split(group_var_dat, f=group_var_dat$group_index) my_cluster ## $`1` ## group_index var_name ## 1 1 X1 ## 4 1 X5 ## ## $`2` ## group_index var_name ## 2 2 X2 ## 3 2 X3 ## 5 2 X4 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ## References ======= # References &gt;&gt;&gt;&gt;&gt;&gt;&gt; 56eeb42d87bc29311ec57c37bae5be9a4b59edac [(https://stackoverflow.com/questions/39482364/group-of-highly-correlated-variables]((https://stackoverflow.com/questions/39482364/group-of-highly-correlated-variables) igraph - The network analysis package - webpage "],["relabel-study-names-into-a-numeric-sequence.html", "Section 8 Relabel study names into a numeric sequence 8.1 Introduction 8.2 Create data 8.3 Transform an arm-based data table to a study-based data table 8.4 References", " Section 8 Relabel study names into a numeric sequence 8.1 Introduction I have read a tutorial about how to use Bayesian network meta analysis. In that, to use the package, I have to relabel study names into a numeric sequence. So, this is the idea of the data that I want: suppressPackageStartupMessages(library(tidyverse)) ## # A tibble: 10 × 2 ## Study Study_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 B 2 ## 6 B 3 ## 7 B 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 8.2 Create data Study &lt;- c(&quot;E&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;D&quot; ) data &lt;- tibble(Study) data &lt;- data %&gt;% arrange(Study) # THIS STEP IS ESSENTIAL n_occur &lt;- data.frame(table(data$Study)) n_occur ## Var1 Freq ## 1 A 2 ## 2 B 3 ## 3 C 1 ## 4 D 2 ## 5 E 2 Stu_num_id &lt;- c() for (i in 1:dim(n_occur)[1]){ num_id &lt;- rep(i, times = n_occur$Freq[i]) Stu_num_id &lt;- Stu_num_id %&gt;% append(num_id) } Note: To make the study is appear correctly, you will need to arrange your studies based on alphabet order data &lt;- data %&gt;% cbind(Stu_num_id) data ## Study Stu_num_id ## 1 A 1 ## 2 A 1 ## 3 B 2 ## 4 B 2 ## 5 B 2 ## 6 C 3 ## 7 D 4 ## 8 D 4 ## 9 E 5 ## 10 E 5 8.2.1 What if we want to keep the order of Study names as they were Study &lt;- c(&quot;E&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;D&quot;) Study_num_id &lt;- c(1L, 1L, 2L, 2L, 2L, 3L, 4L, 4L, 5L, 5L) data &lt;- tibble(Study, Study_num_id) data ## # A tibble: 10 × 2 ## Study Study_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 B 2 ## 6 B 3 ## 7 B 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 data &lt;- data %&gt;% select(-c(&quot;Study_num_id&quot;)) n_occur &lt;- data.frame(table(data$Study)) n_occur ## Var1 Freq ## 1 A 2 ## 2 B 3 ## 3 C 1 ## 4 D 2 ## 5 E 2 I don’t think this is a clever way of doing this (especially with data having many studies). Study_name_unique &lt;- data %$% Study %&gt;% unique() Study_name_unique ## [1] &quot;E&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; Study &lt;- c() Stu_num_id &lt;- c() for (i in 1:dim(n_occur)[1]){ study &lt;- rep(Study_name_unique[i], times= n_occur$Freq[i]) Study &lt;- Study %&gt;% append(study) num_id &lt;- rep(i, times = n_occur$Freq[i]) Stu_num_id &lt;- Stu_num_id %&gt;% append(num_id) } Study_Studyid_dat &lt;- tibble(Study, Stu_num_id) Study_Studyid_dat ## # A tibble: 10 × 2 ## Study Stu_num_id ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 E 1 ## 3 A 2 ## 4 A 2 ## 5 A 2 ## 6 B 3 ## 7 C 4 ## 8 C 4 ## 9 D 5 ## 10 D 5 Now, we have a table with Study name and Study id with the original of Study name oder. If we have your original data with many more columns, what we need to do is just joining the two data tables. 8.3 Transform an arm-based data table to a study-based data table Treat &lt;- c(&quot;T&quot;, &quot;P&quot;, &quot;P&quot;, &quot;T&quot;, &quot;O&quot;, &quot;T&quot;, &quot;T&quot;, &quot;P&quot;, &quot;P&quot;, &quot;T&quot;) N &lt;- c(12, 23, 45, 78, 12, 2 , 4, 6, 8, 9) Total &lt;- c(222, 344, 222, 445, 224, 677, 345, 446, 234, 467) data &lt;- data %&gt;% cbind(Treat) %&gt;% cbind(N) %&gt;% cbind(Total)%&gt;% mutate(Treat = factor(Treat)) data ## Study Treat N Total ## 1 E T 12 222 ## 2 E P 23 344 ## 3 A P 45 222 ## 4 A T 78 445 ## 5 B O 12 224 ## 6 B T 2 677 ## 7 B T 4 345 ## 8 C P 6 446 ## 9 D P 8 234 ## 10 D T 9 467 data %&gt;% pivot_wider(names_from = Treat, values_from = c(N,Total)) ## # A tibble: 5 × 7 ## Study N_T N_P N_O Total_T Total_P Total_O ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 E &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 2 A &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 3 B &lt;dbl [2]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [2]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; ## 4 C &lt;NULL&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;NULL&gt; ## 5 D &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; &lt;dbl [1]&gt; &lt;dbl [1]&gt; &lt;NULL&gt; 8.4 References Doing Meta-Analysis in R: A Hands-on Guide: Network Meta-Analysis Performing Arm-Based Network Meta-Analysis in R with the pcnetmeta Package "],["mutate-many-columns-conditionally.html", "Section 9 Mutate many columns conditionally 9.1 Or we can apply fancier mutate with our custom function 9.2 Use mutate with group_by and custom function 9.3 Create many new columns in R using names from a string vector 9.4 Reference", " Section 9 Mutate many columns conditionally suppressPackageStartupMessages(library(tidyverse)) data &lt;- data.frame( x1 = 1:4, x2 = c(0, 3, 1,4), x3 = c(1, 4, 23, 0), y4 = 0:3) data ## x1 x2 x3 y4 ## 1 1 0 1 0 ## 2 2 3 4 1 ## 3 3 1 23 2 ## 4 4 4 0 3 In case there are not many columns that we need to mutate and we are fine to type them all manually data %&gt;% mutate_at(c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;), ~ ifelse(.&gt;= 1, 1, 0)) ## x1 x2 x3 y4 ## 1 1 0 1 0 ## 2 1 1 1 1 ## 3 1 1 1 2 ## 4 1 1 0 3 In case there are many columns that we want to mutate, we may need to create a vector containing the names of the columns that we want to mutate, then plug in the mutate_at x_col &lt;- colnames(data) %&gt;% str_subset((&quot;x&quot;)) data %&gt;% mutate_at(x_col, ~ ifelse(.&gt;= 1, 1, 0) ) ## x1 x2 x3 y4 ## 1 1 0 1 0 ## 2 1 1 1 1 ## 3 1 1 1 2 ## 4 1 1 0 3 # Or add all columns in x_col by 1 by using data %&gt;% mutate_at(x_col, ~ .+1) ## x1 x2 x3 y4 ## 1 2 1 2 0 ## 2 3 4 5 1 ## 3 4 2 24 2 ## 4 5 5 1 3 9.1 Or we can apply fancier mutate with our custom function my_funct &lt;- function(x){ # x &lt;- as.numeric(x) x &lt;- x+1 return(x) } ## Apply the custom function in ## Old way: use funs (deprecated) # data %&gt;% mutate_at(col, funs(x = my_funct(.))) # New way, using list, according to [dplyr 1.1.2 document](https://dplyr.tidyverse.org/reference/funs.html) data %&gt;% mutate_at(x_col, list(~ my_funct(.))) ## x1 x2 x3 y4 ## 1 2 1 2 0 ## 2 3 4 5 1 ## 3 4 2 24 2 ## 4 5 5 1 3 9.2 Use mutate with group_by and custom function data &lt;- data.frame(group_name= c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;), x1 = 1:4, x2 = c(0, 3, 1,4), x3 = c(1, 4, 23, 0), y4 = 0:3) data ## group_name x1 x2 x3 y4 ## 1 a 1 0 1 0 ## 2 a 2 3 4 1 ## 3 b 3 1 23 2 ## 4 b 4 4 0 3 data %&gt;% group_by(group_name) %&gt;% mutate_at(x_col, ~sum(.)) ## # A tibble: 4 × 5 ## # Groups: group_name [2] ## group_name x1 x2 x3 y4 ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 a 3 3 5 0 ## 2 a 3 3 5 1 ## 3 b 7 5 23 2 ## 4 b 7 5 23 3 9.3 Create many new columns in R using names from a string vector 9.3.1 We will create three columns (named new_#) that follow new_# = sum(x#+ 1) ## Original data data &lt;- data.frame(group_name= c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;), x1 = 1:4, x2 = c(0, 3, 1,4), x3 = c(1, 4, 23, 0), y4 = 0:3) data ## group_name x1 x2 x3 y4 ## 1 a 1 0 1 0 ## 2 a 2 3 4 1 ## 3 b 3 1 23 2 ## 4 b 4 4 0 3 ## Now, We will create three columns (named new_#) that follow new_# = sum(x#+ 1) new_col_name_v &lt;- c(&quot;new_1&quot;, &quot;new_2&quot;, &quot;new_3&quot;) for(new_col in new_col_name_v) { refer_col &lt;- paste0(&quot;x&quot;, as.character(parse_number(new_col))) cat(&quot;refer_col: &quot;, refer_col ) data &lt;- data %&gt;% mutate(!!new_col := sum(.data[[refer_col]])) } ## refer_col: x1refer_col: x2refer_col: x3 data ## group_name x1 x2 x3 y4 new_1 new_2 new_3 ## 1 a 1 0 1 0 10 8 28 ## 2 a 2 3 4 1 10 8 28 ## 3 b 3 1 23 2 10 8 28 ## 4 b 4 4 0 3 10 8 28 9.3.2 Another example will explore how we can create many new columns (new_column: new_#) using a custom function on other columns (refer_col: x#) in data, and this custom function depends on not only the refer column but also other elements in a list. ## Original data data &lt;- data.frame(group_name= c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;), x1 = 1:4, x2 = c(0, 3, 1,4), x3 = c(1, 4, 23, 0), y4 = 0:3) data ## group_name x1 x2 x3 y4 ## 1 a 1 0 1 0 ## 2 a 2 3 4 1 ## 3 b 3 1 23 2 ## 4 b 4 4 0 3 ## ## Now, We will create three columns (named new_#) that follow ## new_# = 1 if x# %in% b#, and ## new_# = 0 otherwise ## It looks long in this example, and may not worth doing this way, ## but when we have huge new columns that we want to create, it will be worth preccesing this way :) new_col_name_v &lt;- c(&quot;new_1&quot;, &quot;new_2&quot;, &quot;new_3&quot;) b1 &lt;- c(2, 3, 4, 5) b2 &lt;- c(1, 2, 3, 4) b3 &lt;- c(0, 4, 5, 6) b_list &lt;- list(b1, b2, b3) for(i in 1:length(new_col_name_v)) { new_col &lt;- new_col_name_v[i] cat(&quot;new_col:&quot;, new_col, &quot;\\n&quot;) refer_col &lt;- paste0(&quot;x&quot;, as.character(parse_number(new_col))) cat(&quot;refer_col:&quot;, refer_col , &quot;\\n&quot;) data &lt;- data %&gt;% mutate(!!new_col := if_else(.data[[refer_col]] %in% b_list[[i]], 1, 0)) } ## new_col: new_1 ## refer_col: x1 ## new_col: new_2 ## refer_col: x2 ## new_col: new_3 ## refer_col: x3 data ## group_name x1 x2 x3 y4 new_1 new_2 new_3 ## 1 a 1 0 1 0 0 0 0 ## 2 a 2 3 4 1 1 1 1 ## 3 b 3 1 23 2 1 1 0 ## 4 b 4 4 0 3 1 1 1 9.4 Reference https://dplyr.tidyverse.org/reference/mutate.html https://www.tidyverse.org/blog/2019/06/rlang-0-4-0/ "],["igraph.html", "Section 10 Igraph 10.1 About id of subgraph in igraph 10.2 What if our original graph has nodes’name taken from natural number set 10.3 Induce subgraph 10.4 Reference", " Section 10 Igraph 10.1 About id of subgraph in igraph suppressPackageStartupMessages(library(tidyverse)) suppressPackageStartupMessages(library(igraph)) One of the problem when I work with igraph is that the index of the nodes will be reset to start from 0. In this section, I would like to explore how it work and make sure that I get the node_id when doing graph sub-sampling. 10.1.1 Create original graph g &lt;- graph_from_literal(A-B:C:I, B-A:C:D, C-A:B:E:H, D-B:E:F, E-C:D:F:H, F-D:E:G, G-F:H, H-C:E:G:I, I-A:H) g ## IGRAPH 6868024 UN-- 9 14 -- ## + attr: name (v/c) ## + edges from 6868024 (vertex names): ## [1] A--B A--C A--I B--C B--D C--E C--H I--H D--E D--F E--H E--F H--G F--G plot(g) Here is what happen when we get node of g and edges of g: it shows the nodes-indexs start from 1, node the actual name attribute of the graph g, we can only get edge_indexes from the below cat(&quot;Node indexes of g: &quot;, V(g)) ## Node indexes of g: 1 2 3 4 5 6 7 8 9 cat(&quot;\\nEdges of g: &quot;, E(g)[.from(V(g))]) ## ## Edges of g: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 to get the actual name of the nodes, we need to call cat(&quot;Node of g: &quot;, V(g)$name) ## Node of g: A B C I D E H F G cat(&quot;\\nEdges of g: &quot;, E(g)[.from(V(g)$name)]) ## ## Edges of g: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 10.1.2 What happen with the subgraph when we do Random node sampling The below shows that it is fine to do sampling from V(g). Besides, when g has a “name” attribute, its subgraph will also inherit the same attribute. # A function to do random node sampling do_random_node_sampling1 &lt;- function(org_igraph, n_node_to_sample) { ## IN: ## org_igraph: original igraph that we will sample from ## n_node_to_sample: the number of node that we will sample ## OUT: ## an (igraph) sub-graph sampled from the org_igraph org_net_all_node &lt;- V(org_igraph) sample_nodes &lt;- sample(org_net_all_node, n_node_to_sample, replace = FALSE) ## Since we just random sampling nodes, we have to induce to get a subgraph sample_subgraph &lt;- subgraph(org_igraph, vids = sample_nodes) return(sample_subgraph) } set.seed(3726) sample1 &lt;- do_random_node_sampling1(g, 5) sample1 ## IGRAPH 68846f5 UN-- 5 4 -- ## + attr: name (v/c) ## + edges from 68846f5 (vertex names): ## [1] A--C A--I C--H I--H plot(sample1) V(sample1) ## + 5/5 vertices, named, from 68846f5: ## [1] A C I H F 10.1.3 How to save a subgraph in the way that we can keep nodes’ name To save a subgraph in order to compare with original graph (e.g. if subgraph’s degree-distribution reflexs the original_graph’s degree distribution). We sometime want keep their name, not their indexes. This is a way that we can do that as_data_frame(sample1) ## from to ## 1 A C ## 2 A I ## 3 C H ## 4 I H 10.2 What if our original graph has nodes’name taken from natural number set We don’t have be worried, it will work the same as when nodes’name taken from alphabet-character set set.seed(645654) data &lt;- data.frame(from=sample(c(1:10),10, replace = TRUE), to=sample(c(1:10),10, replace = TRUE) ) data ## from to ## 1 3 4 ## 2 4 2 ## 3 1 5 ## 4 10 7 ## 5 5 7 ## 6 2 1 ## 7 3 1 ## 8 7 2 ## 9 8 6 ## 10 1 4 g &lt;- graph_from_data_frame(data, directed = FALSE) g ## IGRAPH 68a2c62 UN-- 9 10 -- ## + attr: name (v/c) ## + edges from 68a2c62 (vertex names): ## [1] 3 --4 4 --2 1 --5 10--7 5 --7 1 --2 3 --1 2 --7 8 --6 4 --1 plot(g) 10.2.1 Convert a graph to an adjacency matrix (adj_mtx1 &lt;- as_adjacency_matrix(g)) ## 9 x 9 sparse Matrix of class &quot;dgCMatrix&quot; ## 3 4 1 10 5 2 7 8 6 ## 3 . 1 1 . . . . . . ## 4 1 . 1 . . 1 . . . ## 1 1 1 . . 1 1 . . . ## 10 . . . . . . 1 . . ## 5 . . 1 . . . 1 . . ## 2 . 1 1 . . . 1 . . ## 7 . . . 1 1 1 . . . ## 8 . . . . . . . . 1 ## 6 . . . . . . . 1 . 10.3 Induce subgraph For illustration purpose, let get the original network g and the subgraph1 as below: g &lt;- graph_from_literal(A-B:C:I, B-A:C:D, C-A:B:E:H, D-B:E:F, E-C:D:F:H, F-D:E:G, G-F:H, H-C:E:G:I, I-A:H) g ## IGRAPH 68baff8 UN-- 9 14 -- ## + attr: name (v/c) ## + edges from 68baff8 (vertex names): ## [1] A--B A--C A--I B--C B--D C--E C--H I--H D--E D--F E--H E--F H--G F--G plot(g) sample1 &lt;- sample1 + vertices(&quot;B&quot;, &quot;D&quot;) plot(sample1) Here is how to have an induced subgraph that will induce edges to the subgraph. We see from the plot below that we have gotten an induced sub-graph induce_subgraph1 &lt;- induced_subgraph(g, V(sample1)$name) plot(induce_subgraph1) What happen if we want to induce subgraph2 to graph g when subgraph1 has a node that is not avaiable in the graph g subgraph2 &lt;- sample1 + vertices(&quot;Z&quot;) ## induce_subgraph2 &lt;- induced_subgraph(g, V(subgraph2)$name) plot(induce_subgraph2) it will produce the error “Error in as_igraph_vs(graph, vids) : Invalid vertex names” 10.4 Reference https://igraph.org/ "],["igraph-get-global-statistics-of-an-igraph-object.html", "Section 11 Igraph: Get global statistics of an igraph object 11.1 Goal: compute some global statistics of a igraph 11.2 Compute all clustering coefficients 11.3 Compute all distances between two nodes of a graph 11.4 Reference", " Section 11 Igraph: Get global statistics of an igraph object suppressPackageStartupMessages(library(tidyverse)) suppressPackageStartupMessages(library(igraph)) ## This way will NOT include loops in the edge set # g &lt;- make_graph(~ 1--1, 2--3, 3--3, 4--5, 5--6, 6--7,5--7, 8--9, 9--10, 11--10, 11--11, 5--10, 11--11, 12--12, 13--13 ) # g; plot(g) ## This way will include loops in the edge set graph_data &lt;- data.frame( from = c(1, 2, 3, 4, 5, 6, 5, 8, 9), to = c(1, 3, 3, 5, 6, 7, 7,9,9) ) graph_edgelist &lt;- as.matrix(graph_data) g &lt;- igraph::graph_from_edgelist(graph_edgelist, directed=FALSE) g; plot(g) ## IGRAPH 68ebab2 U--- 9 9 -- ## + edges from 68ebab2: ## [1] 1--1 2--3 3--3 4--5 5--6 6--7 5--7 8--9 9--9 11.1 Goal: compute some global statistics of a igraph Here is a function to compute some global statistics of the graph g compt_global_stat &lt;- function(igraph_object) { ## igraph_object: an igraph object ## ## Clustering coefficient: the degree to which nodes in a graph tend to cluster together clust_coef &lt;- transitivity(igraph_object, type = &quot;average&quot;) ## Average-distance: avg(the length of the shortest path between these two locations along the network.) avg_dist &lt;- mean_distance(igraph_object, details = F) ## density: ratio of the number of edges and the number of possible edges. density &lt;- edge_density(igraph_object, loops= T) ## diameter: the distance between the two most distance nodes in the network ## If a graph is not connected, the diameter() function will return the diameter of the largest connected component diameter &lt;- diameter(igraph_object, unconnected=TRUE) ## glob_char_tibble &lt;- tibble(clust_coef = clust_coef, avg_dist = avg_dist, density = density, diameter = diameter) # write_csv(glob_char_tibble, file.path(direction, file_name)) return(glob_char_tibble) } ## (glob_char_table &lt;- compt_global_stat(g)) ## # A tibble: 1 × 4 ## clust_coef avg_dist density diameter ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.778 1.25 0.2 2 11.2 Compute all clustering coefficients The above code is for computing global_clustering_coefficient = average( clustering_coefficient of all nodes in a graph). Here is how we can compute clustering for all node_id of a graph g when available (the isolated and degree=0 nodes have clustering_coefficient = NaN). comp_coef_clus_dat_f &lt;- function(igraph_object){ clust_coef_dat &lt;- tibble(node_id = as_ids(V(igraph_object)), clus_coef = transitivity(igraph_object, type=c(&quot;local&quot;), vids = V(igraph_object))) %&gt;% ## The isolated and degree=1 nodes have clustering_coefficient not available (=NaN), we can exclude the information of those nodes filter(!is.na(clus_coef)) return(clust_coef_dat) } (clust_cof_tab &lt;- comp_coef_clus_dat_f(g)) ## # A tibble: 3 × 2 ## node_id clus_coef ## &lt;int&gt; &lt;dbl&gt; ## 1 5 0.333 ## 2 6 1 ## 3 7 1 11.3 Compute all distances between two nodes of a graph Distance of a node to itself is 0, and any pair of nodes that are not connected have distance = Inf. We can exclude those pairs if we just want to have the distances of connected nodes. Way1 and way 2: can be applied when we have a small igraph_object. These functions will NOT work when we have a big igraph object with too many nodes since we create a matrix with row and column indexes are node_indexes and matrix-element_values are their distances comp_distance_tab_f &lt;- function(igraph_object){ ## igraph_object: an (undirected, connected/unconnected) igraph ## OUT: a table with unique pair of nodes (node_from and node_to) and their distances (dist_mtx &lt;- distances(igraph_object)) Index&lt;-which(upper.tri(dist_mtx,diag=FALSE),arr.ind=TRUE) distance_tab &lt;- cbind(Index,dist_mtx[Index]) %&gt;% as.data.frame() %&gt;% rename(node_from = &quot;row&quot;, node_to = &quot;col&quot;, distance = &quot;V3&quot;) %&gt;% # The pairs of nodes that are not connected have distance = Inf, We can exclude them filter(!distance == Inf) return(distance_tab) } ## (distance_table &lt;- comp_distance_tab_f(g)) ## node_from node_to distance ## 1 2 3 1 ## 2 4 5 1 ## 3 4 6 2 ## 4 5 6 1 ## 5 4 7 2 ## 6 5 7 1 ## 7 6 7 1 ## 8 8 9 1 # cat(&quot;average(distance): &quot;, mean(distance_table$distance)) Way2: This way will NOT work when the igraph_object is big comp_distance_tab_way2_f &lt;- function(igraph_object){ igraph_node_id &lt;- as_ids(V(igraph_object)) dist_dat &lt;- combn(igraph_node_id, 2) %&gt;% t() %&gt;% as.data.frame() %&gt;% dplyr::rename(node_from = &quot;V1&quot;, node_to = &quot;V2&quot;) distance &lt;- map2(dist_dat$node_from, dist_dat$node_to, ~igraph::distances(igraph_object,.x, .y)) %&gt;% unlist() dist_dat &lt;- cbind(dist_dat, distance) %&gt;% filter(!distance == Inf) return(dist_dat) } comp_distance_tab_way2_f(g) ## node_from node_to distance ## 1 2 3 1 ## 2 4 5 1 ## 3 4 6 2 ## 4 4 7 2 ## 5 5 6 1 ## 6 5 7 1 ## 7 6 7 1 ## 8 8 9 1 Way3 : This way will return a vector of all available distances in the graph but no further information about the pair of node. This way may work for big igraph objects comp_distance_f &lt;- function(igraph_object){ distance_l &lt;- c() igraph_node_id_l &lt;- as_ids(V(igraph_object)) for (node_id1 in igraph_node_id_l){ for (node_id2 in igraph_node_id_l){ if (node_id1 &gt;= node_id2) { next } else { distance = distances(igraph_object,node_id1,node_id2) if (distance!=Inf){distance_l &lt;- distance_l %&gt;% append(distance)} # cat(&quot;\\n&quot;, node_id1, node_id2) }}} return(distance_l) } comp_distance_f(g) ## [1] 1 1 2 2 1 1 1 1 11.4 Reference https://igraph.org/ https://ona-book.org/paths-distance.html "],["igraph-split-a-graphs-nodes-in-to-set-isolated-and-non_isolated-nodes.html", "Section 12 Igraph: split a graph’s nodes in to set isolated and non_isolated nodes 12.1 Goal: we have a graph g, and we want to split it into two data, one contains isolated nodes, and another data contains edges created from non-isolated nodes", " Section 12 Igraph: split a graph’s nodes in to set isolated and non_isolated nodes 12.1 Goal: we have a graph g, and we want to split it into two data, one contains isolated nodes, and another data contains edges created from non-isolated nodes suppressPackageStartupMessages(library(tidyverse)) suppressPackageStartupMessages(library(igraph)) Now, we will create a graph with 13 nodes with attribute “name” from 1-13. This graph has isolated nodes are the nodes have name in \\(\\{1, 12, 13 \\}\\) and other nodes are non_isolated nodes ## This way will NOT include loops in the edge set # g &lt;- make_graph(~ 1--1, 2--3, 3--3, 4--5, 5--6, 6--7,5--7, 8--9, 9--10, 11--10, 11--11, 5--10, 11--11, 12--12, 13--13 ) # g; plot(g) ## This way will include loops in the edge set graph_data &lt;- data.frame( from = c(1, 2, 3, 4, 5, 6, 5, 8, 9, 11, 11, 5, 11, 12, 13), to = c(1, 3, 3, 5, 6, 7, 7, 9,10, 10, 11,10, 11, 12, 13 ) ) graph_edgelist &lt;- as.matrix(graph_data) g &lt;- igraph::graph_from_edgelist(graph_edgelist, directed=FALSE) g; plot(g) ## IGRAPH 6929817 U--- 13 15 -- ## + edges from 6929817: ## [1] 1-- 1 2-- 3 3-- 3 4-- 5 5-- 6 6-- 7 5-- 7 8-- 9 9--10 10--11 ## [11] 11--11 5--10 11--11 12--12 13--13 Here is a function to split the above graph g it into two data, one contains isolated nodes, and another data contains edges created from non-isolated nodes write_isolated_nonisolated_subgraph_dat &lt;- function(igraph_object) { ## In: igraph_object: an igraph object ## Out: a data frame that contains the data of the non_isolated_subgraph with indexes gotten from the original igraph_object ## the indexes are set as character to prevent igraph to reset the index, so that we can keep their original values isolated_node_l &lt;- which(degree(igraph_object, loops = FALSE)==0) ## Find isolated node index ## isolated_subgraph_dat &lt;- isolated_node_l %&gt;% as.data.frame() %&gt;% rename(name = &quot;.&quot;) non_isolated_subgraph_dat &lt;- igraph_object %&gt;% igraph::as_data_frame() %&gt;% filter(!from %in% isolated_node_l) ## # write.table(isolated_subgraph_dat, file.path(direction, &quot;isolated_subgraph_dat.txt&quot;), row.names = F, col.names = F) # write.table(non_isolated_subgraph_dat, file.path(direction, &quot;non_isolated_subgraph_dat.txt&quot;), row.names = F, col.names = F) return(list(isolated_subgraph_dat = isolated_subgraph_dat, non_isolated_subgraph_dat = non_isolated_subgraph_dat)) } our_result &lt;- write_isolated_nonisolated_subgraph_dat(g) our_result$isolated_subgraph_dat ## name ## 1 1 ## 2 12 ## 3 13 our_result$non_isolated_subgraph_dat ## from to ## 1 2 3 ## 2 3 3 ## 3 4 5 ## 4 5 6 ## 5 6 7 ## 6 5 7 ## 7 8 9 ## 8 9 10 ## 9 10 11 ## 10 11 11 ## 11 5 10 ## 12 11 11 "],["nair-package.html", "Section 13 NAIR package 13.1 plot network with size of nodes based on their abundance 13.2 Plot the data with node_size by their abundance (CloneCount)", " Section 13 NAIR package NAIR Network-Analysis-for-Repertoire-Sequencing link 13.1 plot network with size of nodes based on their abundance In the below example, we would like to plot the network without isolated nodes and the nodes size follow CloneCount. suppressPackageStartupMessages(library(NAIR)) suppressPackageStartupMessages(library(tidyverse)) 13.1.1 Create toy example ## toy_data &lt;- simulateToyData() toy_data %&gt;% head() ## CloneSeq CloneFrequency CloneCount SampleID ## 1 TTGAGGAAATTCG 0.007873775 3095 Sample1 ## 2 GGAGATGAATCGG 0.007777102 3057 Sample1 ## 3 GTCGGGTAATTGG 0.009094910 3575 Sample1 ## 4 GCCGGGTAATTCG 0.010160859 3994 Sample1 ## 5 GAAAGAGAATTCG 0.009336593 3670 Sample1 ## 6 AGGTGGGAATTCG 0.010369470 4076 Sample1 13.1.2 Generate network for data net &lt;- generateNetworkObjects(toy_data, &quot;CloneSeq&quot;, drop_isolated_nodes = TRUE) ## Computing network edges based on a max hamming distance of 1... Done. ## Network contains 122 nodes (after removing isolated nodes). net$igraph ## IGRAPH 6955fd4 UNW- 122 251 -- ## + attr: name (v/c), weight (e/n) ## + edges from 6955fd4 (vertex names): ## [1] GGGGGAGAATTGC--GGGGGGGAATTGC AGGGGGAAATTGG--AGGGGGGAATTGG ## [3] AGGGGGGAATTGG--AGGGGAGAATTGG GGGGGGGAATTGC--GGGGGGGAATTGG ## [5] AGGGGGGAATTGG--GGGGGGGAATTGG GGGGGGGAATTGG--GGAGGGGAATTGG ## [7] GGGGGGGAATTGG--GGAGGGGAATTGG GGAGGGGAATTGG--GGAGGGGAATTGG ## [9] GGGGGAGAATTGC--GGGGGAGAATTGG AGGGGAGAATTGG--GGGGGAGAATTGG ## [11] GGGGGGGAATTGG--GGGGGAGAATTGG GGGGGGGAATTGC--GGGGGGGAATTGG ## [13] AGGGGGGAATTGG--GGGGGGGAATTGG GGGGGGGAATTGG--GGGGGGGAATTGG ## [15] GGAGGGGAATTGG--GGGGGGGAATTGG GGAGGGGAATTGG--GGGGGGGAATTGG ## + ... omitted several edges net$node_data ## CloneSeq CloneFrequency CloneCount SampleID ## 2 GGAGATGAATCGG 0.007777102 3057 Sample1 ## 5 GAAAGAGAATTCG 0.009336593 3670 Sample1 ## 8 GGGGAGAAATTGG 0.006220155 2445 Sample1 ## 11 GGGGGAGAATTGC 0.012969469 5098 Sample1 ## 12 GGGGGGGAATTGC 0.009079646 3569 Sample1 ## 13 AGGGGGAAATTGG 0.014941093 5873 Sample1 ## 14 GGTTAGGAATTCG 0.011582972 4553 Sample1 ## 17 AGGGGGGAATTGG 0.006243052 2454 Sample1 ## 18 AGGGGAGAATTGG 0.008120546 3192 Sample1 ## 24 GGGGGGGAATTGG 0.010344029 4066 Sample1 ## 25 GGAGGGGAATTGG 0.009685125 3807 Sample1 ## 28 GGAGGGGAATTGG 0.014495888 5698 Sample1 ## 29 GGAAAGAAATTGG 0.011921328 4686 Sample1 ## 31 GGGGGAGAATTGG 0.016001954 6290 Sample1 ## 33 GAGGGGGAATTG 0.011318393 4449 Sample1 ## 35 GGGGGGGAATTGG 0.009524851 3744 Sample1 ## 36 GGGGTGGAATTGG 0.012669273 4980 Sample1 ## 37 GGGAGGGAATTGG 0.006339725 2492 Sample1 ## 38 GAGGCGGAATCGG 0.007074950 2781 Sample1 ## 40 GAGGGGGAATTGC 0.012203716 4797 Sample1 ## 42 GGGAAGGAATCGG 0.012397062 4873 Sample1 ## 43 GGAGGGGAATCGG 0.007530331 2960 Sample1 ## 45 GGGCGGGAATTGC 0.006779842 2665 Sample1 ## 46 TGGTCGGAATTGG 0.012854988 5053 Sample1 ## 47 GGGTGAAAATTGG 0.010926612 4295 Sample1 ## 51 GGGGAGAAATTGG 0.009682581 3806 Sample1 ## 53 GGGTGGGAATTGG 0.013697062 5384 Sample1 ## 55 GAGGGGGAATTGG 0.013058510 5133 Sample1 ## 56 AGCGGAGAATTGG 0.011249704 4422 Sample1 ## 57 GGAGCTGAATCGG 0.013335810 5242 Sample1 ## 58 GGGGGAGAATTGG 0.009395106 3693 Sample1 ## 60 AGGGAGGAATTC 0.009092366 3574 Sample1 ## 62 GAGGGGGAATTCG 0.011842463 4655 Sample1 ## 63 TGGGGGGAATTGG 0.011537180 4535 Sample1 ## 64 TGAGGGAAATTGG 0.004574167 1798 Sample1 ## 65 GGGGAGGAATCGG 0.011585516 4554 Sample1 ## 67 AGGGGGGAATTC 0.009186495 3611 Sample1 ## 68 AGGTCGGAATTGG 0.008301173 3263 Sample1 ## 71 CGAGGGAAATTGG 0.010135419 3984 Sample1 ## 72 GGGGGGAAATTGG 0.010870644 4273 Sample1 ## 73 GTGGTGGAATTGG 0.008352053 3283 Sample1 ## 74 AGGGGGGAATTGG 0.012206260 4798 Sample1 ## 75 GGATAGGAATTCG 0.007827983 3077 Sample1 ## 76 AGTGGAGAATTGG 0.008003521 3146 Sample1 ## 77 AGGGGGGAATTC 0.014572208 5728 Sample1 ## 80 GGGTGAAAATTG 0.010277884 4040 Sample1 ## 81 AGGGGGAAATCGG 0.008797259 3458 Sample1 ## 82 GGAGGCGAATCGG 0.012758315 5015 Sample1 ## 83 GGGGGGGAATTGG 0.016602345 6526 Sample1 ## 86 GGGGGGGAATTGG 0.013389234 5263 Sample1 ## 87 AGGGAGGAATTGG 0.009099998 3577 Sample1 ## 89 GGGGGGGAATTGG 0.006354989 2498 Sample1 ## 90 AGAGGAGAATTGG 0.008303717 3264 Sample1 ## 91 GGGGGAGAATTGC 0.006741682 2650 Sample1 ## 93 GAGGCTGAATCGG 0.011318393 4449 Sample1 ## 96 AGGAGGAAATTGG 0.008306261 3265 Sample1 ## 97 GGGGGGGAATTGG 0.004508023 1772 Sample1 ## 98 GGAACGAAATTGG 0.009013501 3543 Sample1 ## 99 GGAGGGAAATTGC 0.007718589 3034 Sample1 ## 102 AAAATAAAATTGG 0.011245432 4040 Sample2 ## 103 GATAAAAAATTC 0.006961590 2501 Sample2 ## 104 AAAACAAAATTGG 0.009633772 3461 Sample2 ## 105 AAAAAAAAATTG 0.006855816 2463 Sample2 ## 107 AAAAAAGAATTGC 0.012219664 4390 Sample2 ## 108 AAGAAGAAATTG 0.007025611 2524 Sample2 ## 110 AAGAAAAAATTG 0.010059651 3614 Sample2 ## 111 GGAGAGAAATTGC 0.012035952 4324 Sample2 ## 114 AAAATAAAATTC 0.010549551 3790 Sample2 ## 115 GGAAAAAAATTGG 0.013889778 4990 Sample2 ## 116 CAAAAAAAATTC 0.008119536 2917 Sample2 ## 119 AAAAACTAATTGC 0.011498732 4131 Sample2 ## 121 AAAAGAAAATTCG 0.009733979 3497 Sample2 ## 122 GAAAAAGAATTG 0.006410453 2303 Sample2 ## 123 AAAGAGAAATTG 0.010165425 3652 Sample2 ## 125 GAAAAAAAATTG 0.012361624 4441 Sample2 ## 126 AAAGAAAAATTG 0.007100766 2551 Sample2 ## 127 AGAAGAAAATTGC 0.006833548 2455 Sample2 ## 129 AAAAGAGAATTCG 0.007888503 2834 Sample2 ## 131 AAAAAGAAATTG 0.012971216 4660 Sample2 ## 132 AGAGAAAAATCGG 0.005962306 2142 Sample2 ## 134 AAAAATAAATTGC 0.005619932 2019 Sample2 ## 135 AACAAAGAATTC 0.015648964 5622 Sample2 ## 136 AAGCAGAAATTGG 0.009703360 3486 Sample2 ## 137 AGAGAAAAATTC 0.010017898 3599 Sample2 ## 138 AATAAAGAATTC 0.011509866 4135 Sample2 ## 139 TAAAAAAAATTGC 0.008868303 3186 Sample2 ## 143 AAAATAAAATTC 0.008525930 3063 Sample2 ## 144 GAAAAGAAATTG 0.008982428 3227 Sample2 ## 150 GAAAAAAAATTGC 0.012589873 4523 Sample2 ## 152 AGAAAAAAATCGG 0.007958091 2859 Sample2 ## 153 AAAAAAAAATTGC 0.007571182 2720 Sample2 ## 155 ACAAAAGAATTGC 0.012208530 4386 Sample2 ## 156 GAAATAGAATTCG 0.012308737 4422 Sample2 ## 157 AATGAAGAATTC 0.007551697 2713 Sample2 ## 158 AAAAAGTAATTG 0.008915623 3203 Sample2 ## 160 AGAAAAGAATTGC 0.012266984 4407 Sample2 ## 161 AAAACGAAATTG 0.011749249 4221 Sample2 ## 162 AGAGAAGAATTGG 0.010986564 3947 Sample2 ## 163 GAAAAAGAATTCG 0.007799430 2802 Sample2 ## 165 AGGGAAGAATTC 0.013255135 4762 Sample2 ## 168 AAGAAGGAATTGG 0.005739624 2062 Sample2 ## 169 AGAAGAAAATTCG 0.010374189 3727 Sample2 ## 170 AAAGAAAAATTG 0.013578024 4878 Sample2 ## 171 AAAGGAAAATTG 0.012049870 4329 Sample2 ## 174 GAAAAAAAATTC 0.015011538 5393 Sample2 ## 177 GTAAAAAAATTG 0.010674809 3835 Sample2 ## 178 AGAGAAGAATTC 0.008397888 3017 Sample2 ## 179 AAGAAGAAATTGG 0.013230083 4753 Sample2 ## 180 AGAAAAAAATTC 0.009469544 3402 Sample2 ## 181 AGAAGAAAATTGC 0.012854308 4618 Sample2 ## 182 AGAAGAAAATTC 0.009408307 3380 Sample2 ## 183 AAAAACAAATTGC 0.009338719 3355 Sample2 ## 184 GAAGAAAAATTC 0.010012331 3597 Sample2 ## 186 AAAAAAAAATTG 0.009825835 3530 Sample2 ## 187 AAAAAGAAATTG 0.010365838 3724 Sample2 ## 188 AAAAAAAAATTC 0.012008117 4314 Sample2 ## 194 AGAACAAAATTC 0.002162797 777 Sample2 ## 195 AAAAAAAAATTC 0.009697793 3484 Sample2 ## 196 AAAAAGAAATTGC 0.011674094 4194 Sample2 ## 197 AGAAGAAAATTGC 0.012768018 4587 Sample2 ## 199 ACAAGAAAATTC 0.009374904 3368 Sample2 ## 200 AAAAGAAAATTGC 0.010546767 3789 Sample2 net$adjacency_matrix[1:10, 1:10] ## 10 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## [[ suppressing 10 column names &#39;GGAGATGAATCGG&#39;, &#39;GAAAGAGAATTCG&#39;, &#39;GGGGAGAAATTGG&#39; ... ]] ## ## 2 1 . . . . . . . . . ## 5 . 1 . . . . . . . . ## 8 . . 1 . . . . . . . ## 11 . . . 1 1 . . . . . ## 12 . . . 1 1 . . . . 1 ## 13 . . . . . 1 . 1 . . ## 14 . . . . . . 1 . . . ## 17 . . . . . 1 . 1 1 1 ## 18 . . . . . . . 1 1 . ## 24 . . . . 1 . . 1 . 1 13.2 Plot the data with node_size by their abundance (CloneCount) Plot the network with node_color by SampleID and node_size by abundance # Plot network graph net_plot &lt;- plotNetworkGraph( net$igraph, color_nodes_by = net$node_data$SampleID, color_scheme = &quot;viridis&quot;, size_nodes_by = net$node_data$CloneCount, node_size_limits = c(0.5, 3)) print(net_plot) 13.2.1 Plot the network with node_color by Clusterid annd node_size by their abundance (CloneCount) Now, assume that all of the above CloneSeq come from the same Sample (We ignore the column SampleID for now). We want to plot the network with color_node by cluster_id and size_node by abundance (CloneCount) # Run te below command does not help us to have size_node by abundance but can help us get community cluster mynetwork &lt;- buildRepSeqNetwork( toy_data, seq_col = &quot;CloneSeq&quot;, dist_type = &quot;hamming&quot;, dist_cutoff = 1, drop_isolated_nodes = TRUE, #NOTE: We want to keep all nodes (including isolated nodes) output_dir = &quot;D:/r-random-tricks/data/NAIR&quot;, cluster_stats = TRUE, # color_nodes_by = &quot;cluster_id&quot;, # size_nodes_by = my_dat$Count_1, output_name = &quot;MyRepSeqNetwork_nodesizeby_abundance&quot; ) ## Input data contains 200 rows. ## Removing sequences with length fewer than 3 characters... Done. 200 rows remaining. ## Computing network edges based on a max hamming distance of 1... Done. ## Network contains 122 nodes (after removing isolated nodes). ## Computing cluster membership within the network... Done. ## Computing statistics for the 20 clusters in the network... Done. ## Generating graph plot with nodes colored by cluster_id... ## Done. ## Node-level meta-data saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance_NodeMetadata.csv ## Cluster-level meta-data saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance_ClusterMetadata.csv ## Network graph plots saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance.pdf ## Network igraph saved in edgelist format to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance_EdgeList.txt ## Adjacency matrix saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance_AdjacencyMatrix.mtx plotNetworkGraph( mynetwork$igraph, color_nodes_by = mynetwork$node_data$cluster_id, color_scheme = &quot;viridis&quot;, size_nodes_by = mynetwork$node_data$CloneCount, node_size_limits = c(0.5, 3)) 13.2.2 Plot the network with node_color by Clusterid annd node_size by their abundance (CloneCount) when there are extreme values for abundance set.seed(476) toy_data1 &lt;- toy_data[sample(1:nrow(toy_data)), ] %&gt;% mutate(CloneCount = c(sample(c(1: 10), size = 100, replace=TRUE), sample(c(1: 100000), size = 100, replace=TRUE))) toy_data1 %&gt;% head() ## CloneSeq CloneFrequency CloneCount SampleID ## 199 ACAAGAAAATTC 0.009374904 9 Sample2 ## 17 AGGGGGGAATTGG 0.006243052 7 Sample1 ## 19 TCGATGGAATTGG 0.014465359 5 Sample1 ## 112 ATATGAGAATTC 0.006797362 7 Sample2 ## 182 AGAAGAAAATTC 0.009408307 3 Sample2 ## 31 GGGGGAGAATTGG 0.016001954 10 Sample1 # Run te below command does not help us to have size_node by abundance but can help us get community cluster mynetwork1 &lt;- buildRepSeqNetwork( toy_data1, seq_col = &quot;CloneSeq&quot;, dist_type = &quot;hamming&quot;, dist_cutoff = 1, drop_isolated_nodes = TRUE, #NOTE: We want to keep all nodes (including isolated nodes) output_dir = &quot;D:/r-random-tricks/data/NAIR&quot;, cluster_stats = TRUE, # color_nodes_by = &quot;cluster_id&quot;, # size_nodes_by = my_dat$Count_1, output_name = &quot;MyRepSeqNetwork_nodesizeby_abundance1&quot; ) ## Input data contains 200 rows. ## Removing sequences with length fewer than 3 characters... Done. 200 rows remaining. ## Computing network edges based on a max hamming distance of 1... Done. ## Network contains 122 nodes (after removing isolated nodes). ## Computing cluster membership within the network... Done. ## Computing statistics for the 20 clusters in the network... Done. ## Generating graph plot with nodes colored by cluster_id... ## Done. ## Node-level meta-data saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance1_NodeMetadata.csv ## Cluster-level meta-data saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance1_ClusterMetadata.csv ## Network graph plots saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance1.pdf ## Network igraph saved in edgelist format to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance1_EdgeList.txt ## Adjacency matrix saved to file: ## D:/r-random-tricks/data/NAIR/MyRepSeqNetwork_nodesizeby_abundance1_AdjacencyMatrix.mtx plotNetworkGraph( mynetwork1$igraph, color_nodes_by = mynetwork1$node_data$cluster_id, color_scheme = &quot;viridis&quot;, size_nodes_by = mynetwork1$node_data$CloneCount, node_size_limits = c(0.1, 5)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
